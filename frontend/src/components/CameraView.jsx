import React, { useRef, useEffect, useState, useCallback } from 'react';
import { detectObjects, detectVideoFrame, resetTrackingSession } from '../services/api';
import { audioService } from '../services/audioService';
import { t } from '../utils/translations';
import { translateClass, capitalizeFirst } from '../utils/classTranslations';
import ResultsTable from './ResultsTable';

const CameraView = ({ isActive, onClose }) => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const overlayCanvasRef = useRef(null);
  const streamRef = useRef(null);
  const intervalRef = useRef(null);
  const fallbackTimeoutRef = useRef(null);
  const loadedMetadataHandlerRef = useRef(null);
  
  // Request Queue v·ªõi AbortController
  const abortControllerRef = useRef(null);
  const isDetectingRef = useRef(false); // D√πng ref ƒë·ªÉ tr√°nh stale closure
  const skippedFramesRef = useRef(0); // Track skipped frames
  
  // Audio feedback timer (hi·ªán kh√¥ng d√πng cooldown ph·ª©c t·∫°p, nh∆∞ng v·∫´n gi·ªØ ref ƒë·ªÉ d·ªÖ m·ªü r·ªông sau)
  const audioCooldownTimerRef = useRef(null);
  
  // L∆∞u danh s√°ch track_id ƒë√£ ƒë∆∞·ª£c ƒë·ªçc ƒë·ªÉ kh√¥ng ƒë·ªçc l·∫°i
  const announcedTrackIdsRef = useRef(new Set());
  // L∆∞u danh s√°ch detections ƒë√£ ƒë∆∞·ª£c ƒë·ªçc g·∫ßn nh·∫•t ƒë·ªÉ c√≥ th·ªÉ "ƒê·ªçc l·∫°i"
  const lastAnnouncedDetectionsRef = useRef(null);
  
  const [isDetecting, setIsDetecting] = useState(false);
  const [isStreaming, setIsStreaming] = useState(false);
  const [error, setError] = useState(null);
  const [detectionInterval, setDetectionInterval] = useState(500); // ms gi·ªØa c√°c l·∫ßn detect
  const [frameCount, setFrameCount] = useState(0);
  const [lastDetections, setLastDetections] = useState([]); // Gi·ªØ l·∫°i ƒë·ªÉ backward compatibility
  const [activeTracks, setActiveTracks] = useState(new Map()); // track_id -> track data
  const [sessionId] = useState(() => `session_${Date.now()}_${Math.random().toString(36).slice(2, 11)}`); // Unique session ID
  const [fps, setFps] = useState(0); // FPS counter
  const [detectionRate, setDetectionRate] = useState(0); // Detection rate
  const [isAudioEnabled, setIsAudioEnabled] = useState(true); // Tr·∫°ng th√°i b·∫≠t/t·∫Øt audio

  // ƒê·ªìng b·ªô tr·∫°ng th√°i audio v·ªõi audioService
  useEffect(() => {
    audioService.setEnabled(isAudioEnabled);
    if (!isAudioEnabled) {
      audioService.stop();
    }
  }, [isAudioEnabled]);

  // Kh·ªüi ƒë·ªông camera
  const startCamera = useCallback(async () => {
    try {
      setError(null);
      
      // D·ª´ng camera c≈© n·∫øu c√≥
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      
      // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o cleanup ho√†n t·∫•t
      await new Promise(resolve => setTimeout(resolve, 100));
      
      // Y√™u c·∫ßu quy·ªÅn truy c·∫≠p camera
      // ∆Øu ti√™n camera tr∆∞·ªõc cho laptop/desktop, camera sau cho mobile
      const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: isMobile ? 'environment' : 'user' // Camera sau cho mobile, camera tr∆∞·ªõc cho laptop
        }
      });

      streamRef.current = stream;
      
      if (videoRef.current) {
        const video = videoRef.current;
        
        // Set srcObject tr∆∞·ªõc
        video.srcObject = stream;
        
        // ƒê·ª£i video s·∫µn s√†ng
        const handleLoadedMetadata = async () => {
          try {
            // Ki·ªÉm tra readyState tr∆∞·ªõc khi play
            if (video && video.readyState >= 2) {
              await video.play();
              setIsStreaming(true);
            }
          } catch (playError) {
            // X·ª≠ l√Ω l·ªói play m·ªôt c√°ch graceful
            if (playError.name !== 'AbortError' && playError.name !== 'NotAllowedError') {
              console.warn('Video play warning:', playError);
            }
            // V·∫´n set streaming n·∫øu video ƒë√£ load ƒë∆∞·ª£c metadata
            if (video && video.readyState >= 2) {
              setIsStreaming(true);
            }
          }
        };
        
        loadedMetadataHandlerRef.current = handleLoadedMetadata;
        video.addEventListener('loadedmetadata', handleLoadedMetadata, { once: true });
        
        // Fallback: n·∫øu onloadedmetadata kh√¥ng fire, th·ª≠ play sau 500ms
        fallbackTimeoutRef.current = setTimeout(async () => {
          if (video && video.readyState >= 2) {
            try {
              await video.play();
              setIsStreaming(true);
            } catch (playError) {
              if (playError.name !== 'AbortError' && playError.name !== 'NotAllowedError') {
                console.warn('Video play fallback warning:', playError);
              }
              // V·∫´n cho ph√©p streaming n·∫øu video ƒë√£ s·∫µn s√†ng
              if (video.readyState >= 2) {
                setIsStreaming(true);
              }
            }
          }
          fallbackTimeoutRef.current = null;
        }, 500);
      }
    } catch (err) {
      console.error('Error accessing camera:', err);
      
      // C·∫£i thi·ªán error messages d·ª±a tr√™n lo·∫°i l·ªói
      let errorMessage = 'Kh√¥ng th·ªÉ truy c·∫≠p camera.';
      
      if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
        errorMessage = 'Quy·ªÅn truy c·∫≠p camera b·ªã t·ª´ ch·ªëi. Vui l√≤ng cho ph√©p truy c·∫≠p camera trong c√†i ƒë·∫∑t tr√¨nh duy·ªát.';
      } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
        errorMessage = 'Kh√¥ng t√¨m th·∫•y camera. Vui l√≤ng ki·ªÉm tra xem camera ƒë√£ ƒë∆∞·ª£c k·∫øt n·ªëi ch∆∞a.';
      } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {
        errorMessage = 'Camera ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi ·ª©ng d·ª•ng kh√°c. Vui l√≤ng ƒë√≥ng ·ª©ng d·ª•ng kh√°c v√† th·ª≠ l·∫°i.';
      } else if (err.name === 'OverconstrainedError' || err.name === 'ConstraintNotSatisfiedError') {
        errorMessage = 'Camera kh√¥ng h·ªó tr·ª£ y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i.';
      } else if (err.name === 'SecurityError') {
        errorMessage = 'L·ªói b·∫£o m·∫≠t. Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒëang s·ª≠ d·ª•ng HTTPS ho·∫∑c localhost.';
      } else {
        errorMessage = 'Kh√¥ng th·ªÉ truy c·∫≠p camera. Vui l√≤ng ki·ªÉm tra quy·ªÅn truy c·∫≠p v√† th·ª≠ l·∫°i.';
      }
      
      setError(errorMessage);
      if (audioService.isSupported()) {
        audioService.speakSystemMessage('Kh√¥ng th·ªÉ truy c·∫≠p camera', 5);
      }
    }
  }, []);

  // X·ª≠ l√Ω audio feedback cho camera mode
  // Y√™u c·∫ßu: Ch·ªâ ƒë·ªçc ƒë·ªëi t∆∞·ª£ng M·ªöI (track_id m·ªõi), kh√¥ng ƒë·ªçc l·∫°i n·∫øu c√≤n ·ªü ƒë√≥
  const handleCameraAudioFeedback = useCallback((detections) => {
    if (!detections || detections.length === 0) {
      return;
    }

    // L∆∞u l·∫°i danh s√°ch detections ƒë√£ ƒë·ªçc g·∫ßn nh·∫•t ƒë·ªÉ c√≥ th·ªÉ "ƒê·ªçc l·∫°i"
    lastAnnouncedDetectionsRef.current = detections;

    // G·ªçi speakDetections v·ªõi delay c·ªë ƒë·ªãnh 2s gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng
    if (isAudioEnabled) {
      audioService.speakDetections(detections, 2000);
    }
  }, [isAudioEnabled]);

  const stopCamera = useCallback(() => {
    // Cancel pending request
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
    
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
      intervalRef.current = null;
    }

    if (fallbackTimeoutRef.current) {
      clearTimeout(fallbackTimeoutRef.current);
      fallbackTimeoutRef.current = null;
    }

    // Clear audio cooldown timer
    if (audioCooldownTimerRef.current) {
      clearTimeout(audioCooldownTimerRef.current);
      audioCooldownTimerRef.current = null;
    }
    // Reset danh s√°ch track_id ƒë√£ ƒë∆∞·ª£c ƒë·ªçc v√† detections ƒë√£ ƒë·ªçc g·∫ßn nh·∫•t
    announcedTrackIdsRef.current = new Set();
    lastAnnouncedDetectionsRef.current = null;

    if (videoRef.current && loadedMetadataHandlerRef.current) {
      videoRef.current.removeEventListener('loadedmetadata', loadedMetadataHandlerRef.current);
      loadedMetadataHandlerRef.current = null;
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }

    // Reset tracking session ·ªü backend ƒë·ªÉ cleanup
    if (sessionId) {
      resetTrackingSession(sessionId).catch(err => {
        // Ignore errors khi cleanup session (c√≥ th·ªÉ session ƒë√£ b·ªã cleanup t·ª± ƒë·ªông)
        console.warn('Failed to reset tracking session:', err);
      });
    }

    setIsStreaming(false);
    setIsDetecting(false);
    isDetectingRef.current = false;
    setFrameCount(0);
    setLastDetections([]);
    setActiveTracks(new Map()); // Reset tracks
    skippedFramesRef.current = 0;
    setFps(0);
    setDetectionRate(0);
  }, [sessionId]);

  // N√∫t b·∫≠t/t·∫Øt audio
  const handleToggleAudio = useCallback(() => {
    setIsAudioEnabled(prev => !prev);
  }, []);

  // N√∫t "ƒê·ªçc l·∫°i" - ƒë·ªçc l·∫°i nh√≥m ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë·ªçc g·∫ßn nh·∫•t
  const handleRepeatAudio = useCallback(() => {
    const detections = lastAnnouncedDetectionsRef.current;
    if (!detections || detections.length === 0) {
      return;
    }
    audioService.stop();
    if (isAudioEnabled) {
      audioService.speakDetections(detections, 2000);
    }
  }, [isAudioEnabled]);

  // Capture frame v√† g·ª≠i ƒëi detect v·ªõi Request Queue + Frame Skipping + Image Optimization
  const captureAndDetect = useCallback(async () => {
    // Frame Skipping: Skip n·∫øu ƒëang detect
    if (!videoRef.current || !isStreaming || isDetectingRef.current) {
      skippedFramesRef.current += 1;
      return;
    }

    // Cancel request c≈© n·∫øu c√≥
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }

    // T·∫°o AbortController m·ªõi
    const abortController = new AbortController();
    abortControllerRef.current = abortController;
    isDetectingRef.current = true;
    setIsDetecting(true);
    setFrameCount(prev => prev + 1);

    const startTime = performance.now();

    try {
      // Capture frame t·ª´ video
      const video = videoRef.current;
      const canvas = canvasRef.current;
      
      if (!canvas) {
        isDetectingRef.current = false;
        setIsDetecting(false);
        abortControllerRef.current = null;
        return;
      }

      // Image Optimization: Resize ƒë·ªÉ gi·∫£m file size
      const maxWidth = 320; // Gi·∫£m t·ª´ 640 xu·ªëng 320
      const maxHeight = 240; // Gi·∫£m t·ª´ 480 xu·ªëng 240
      const videoWidth = video.videoWidth || 640;
      const videoHeight = video.videoHeight || 480;
      
      // T√≠nh to√°n scale ƒë·ªÉ gi·ªØ aspect ratio
      const scale = Math.min(maxWidth / videoWidth, maxHeight / videoHeight, 1);
      const canvasWidth = Math.floor(videoWidth * scale);
      const canvasHeight = Math.floor(videoHeight * scale);
      
      canvas.width = canvasWidth;
      canvas.height = canvasHeight;
      
      // L∆∞u canvas size th·ª±c t·∫ø v√†o canvas element ƒë·ªÉ d√πng cho bounding box scaling
      canvas._actualWidth = canvasWidth;
      canvas._actualHeight = canvasHeight;
      
      const ctx = canvas.getContext('2d');
      // Draw v·ªõi scale
      ctx.drawImage(video, 0, 0, canvasWidth, canvasHeight);

      // Convert canvas to blob v·ªõi quality th·∫•p h∆°n (0.6 thay v√¨ 0.8)
      try {
        canvas.toBlob(async (blob) => {
          // Check n·∫øu request ƒë√£ b·ªã cancel
          if (abortController.signal.aborted) {
            isDetectingRef.current = false;
            setIsDetecting(false);
            return;
          }

          if (!blob) {
            isDetectingRef.current = false;
            setIsDetecting(false);
            abortControllerRef.current = null;
            return;
          }

          try {
            // T·∫°o File object t·ª´ blob
            const file = new File([blob], `frame_${Date.now()}.jpg`, { type: 'image/jpeg' });
            
            // G·ªçi API detect-video v·ªõi tracking (thay v√¨ detect th√¥ng th∆∞·ªùng)
            const result = await detectVideoFrame(file, 0.25, 0.45, sessionId, abortController.signal);
            
            // Check l·∫°i n·∫øu request ƒë√£ b·ªã cancel
            if (abortController.signal.aborted) {
              return;
            }
            
            const endTime = performance.now();
            const detectionTime = endTime - startTime;
            
            // Update detection rate
            setDetectionRate(prev => {
              const newRate = Math.round(1000 / detectionTime);
              return Math.floor((prev * 0.7) + (newRate * 0.3)); // Moving average
            });
            
            if (result && result.tracks && result.tracks.length > 0) {
              // Update active tracks map
              setActiveTracks(prev => {
                const newTracksMap = new Map(prev);
                
                // Update v·ªõi tracks m·ªõi
                const currentTrackIds = new Set();
                result.tracks.forEach(track => {
                  const trackId = track.track_id;
                  currentTrackIds.add(trackId);
                  newTracksMap.set(trackId, {
                    ...track,
                    last_seen: Date.now()
                  });
                });
                
                // Remove old tracks (kh√¥ng xu·∫•t hi·ªán trong frame n√†y)
                // Gi·ªØ l·∫°i tracks kh√¥ng xu·∫•t hi·ªán < 2 gi√¢y (c√≥ th·ªÉ b·ªã t·∫°m th·ªùi che khu·∫•t)
                const now = Date.now();
                for (const [id, track] of newTracksMap.entries()) {
                  if (!currentTrackIds.has(id)) {
                    if (now - track.last_seen > 2000) {
                      newTracksMap.delete(id);
                    }
                  }
                }
                
                return newTracksMap;
              });
              
              // Convert tracks to detections format cho backward compatibility
              const detectionsForDisplay = result.tracks.map(t => ({
                id: t.track_id,
                class: t.class,
                class_id: t.class_id,
                confidence: t.confidence,
                bbox: t.bbox,
                width: t.bbox[2] - t.bbox[0],
                height: t.bbox[3] - t.bbox[1],
                track_id: t.track_id,
                is_new: t.is_new
              }));
              setLastDetections(detectionsForDisplay);
              
              // AUDIO LOGIC M·ªöI D·ª∞A TR√äN TRACKING:
              // 1. L·ªçc ra c√°c track M·ªöI (ch∆∞a t·ª´ng ƒë∆∞·ª£c ƒë·ªçc)
              const newTracks = result.tracks.filter(t => !announcedTrackIdsRef.current.has(t.track_id));
              
              if (newTracks.length > 0) {
                // N·∫øu audio ƒëang b·∫≠n ƒë·ªçc nh√≥m tr∆∞·ªõc ‚Üí KH√îNG ƒë√°nh d·∫•u ƒë√£ ƒë·ªçc, ƒë·ª£i l·∫ßn sau khi audio r·∫£nh
                if (!audioService.isAnnouncingObjects && audioService.scheduledTimeouts.length === 0) {
                  // 2. Convert tracks m·ªõi sang format detections cho audio
                  const newDetections = newTracks.map(t => ({
                    class: t.class,
                    confidence: t.confidence,
                    bbox: t.bbox
                  }));

                  // 3. Ph√°t audio CH·ªà cho ƒë·ªëi t∆∞·ª£ng m·ªõi
                  handleCameraAudioFeedback(newDetections);

                  // 4. ƒê√°nh d·∫•u c√°c track_id n√†y l√† ƒë√£ ƒë∆∞·ª£c ƒë·ªçc
                  newTracks.forEach(t => {
                    announcedTrackIdsRef.current.add(t.track_id);
                  });
                }
              }

              // 5. Cleanup: n·∫øu track_id kh√¥ng c√≤n trong frame hi·ªán t·∫°i ‚Üí x√≥a kh·ªèi danh s√°ch ƒë√£ ƒë·ªçc
              const currentTrackIds = new Set(result.tracks.map(t => t.track_id));
              announcedTrackIdsRef.current.forEach(id => {
                if (!currentTrackIds.has(id)) {
                  announcedTrackIdsRef.current.delete(id);
                }
              });
            } else {
              // Kh√¥ng c√≥ tracks
              setLastDetections([]);
              // Clear old tracks sau 2 gi√¢y
              setActiveTracks(prev => {
                const newMap = new Map();
                const now = Date.now();
                for (const [id, track] of prev.entries()) {
                  if (now - track.last_seen < 2000) {
                    newMap.set(id, track);
                  }
                }
                return newMap;
              });
              
              // Clear audio cooldown (n·∫øu c√≥)
              if (audioCooldownTimerRef.current) {
                clearTimeout(audioCooldownTimerRef.current);
                audioCooldownTimerRef.current = null;
              }
            }
          } catch (err) {
            // Ignore canceled errors
            if (err.message === 'Request canceled' || abortController.signal.aborted) {
              return;
            }
            console.error('Detection error:', err);
          } finally {
            if (!abortController.signal.aborted) {
              isDetectingRef.current = false;
              setIsDetecting(false);
              abortControllerRef.current = null;
            }
          }
        }, 'image/jpeg', 0.6); // Gi·∫£m quality t·ª´ 0.8 xu·ªëng 0.6
      } catch (blobError) {
        console.error('Error converting canvas to blob:', blobError);
        isDetectingRef.current = false;
        setIsDetecting(false);
        abortControllerRef.current = null;
      }
    } catch (err) {
      console.error('Capture error:', err);
      isDetectingRef.current = false;
      setIsDetecting(false);
      abortControllerRef.current = null;
    }
  }, [isStreaming]);

  // Effect ƒë·ªÉ qu·∫£n l√Ω camera lifecycle
  useEffect(() => {
    if (isActive) {
      startCamera();
    } else {
      stopCamera();
    }

    return () => {
      stopCamera();
    };
  }, [isActive, startCamera, stopCamera]);

  // Effect ƒë·ªÉ b·∫Øt ƒë·∫ßu detection loop v·ªõi frame skipping
  useEffect(() => {
    if (isActive && isStreaming) {
      // Clear interval c≈© n·∫øu c√≥
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      
      // B·∫Øt ƒë·∫ßu detection loop
      // Interval s·∫Ω t·ª± skip frame n·∫øu isDetectingRef.current = true
      intervalRef.current = setInterval(() => {
        captureAndDetect();
      }, detectionInterval);
    } else {
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
      }
    }

    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
      }
    };
  }, [isActive, isStreaming, detectionInterval, captureAndDetect]);

  // FPS counter - Track actual processed frames
  useEffect(() => {
    if (!isStreaming) {
      setFps(0);
      return;
    }

    let lastFrameCount = frameCount;
    const fpsInterval = setInterval(() => {
      const currentFrameCount = frameCount;
      const framesProcessed = currentFrameCount - lastFrameCount;
      setFps(framesProcessed);
      lastFrameCount = currentFrameCount;
    }, 1000);

    return () => clearInterval(fpsInterval);
  }, [isStreaming, frameCount]);

  // Cleanup khi unmount
  useEffect(() => {
    return () => {
      stopCamera();
    };
  }, [stopCamera]);

  // Function ƒë·ªÉ v·∫Ω bounding boxes
  const drawBoundingBoxes = useCallback(() => {
    if (!overlayCanvasRef.current || !videoRef.current) {
      return;
    }

    const overlay = overlayCanvasRef.current;
    const video = videoRef.current;
    
    // L·∫•y k√≠ch th∆∞·ªõc th·ª±c t·∫ø c·ªßa video element (sau khi render)
    const videoRect = video.getBoundingClientRect();
    const videoWidth = video.videoWidth || 640;
    const videoHeight = video.videoHeight || 480;
    
    if (videoWidth === 0 || videoHeight === 0) return;
    
    // Canvas ƒë√£ ƒë∆∞·ª£c resize, l·∫•y size th·ª±c t·∫ø t·ª´ canvas element
    // N·∫øu kh√¥ng c√≥, d√πng default 320x240
    const actualCanvasWidth = canvasRef.current?._actualWidth || 320;
    const actualCanvasHeight = canvasRef.current?._actualHeight || 240;
    
    // Scale factor t·ª´ canvas size th·ª±c t·∫ø v·ªÅ video display size
    const scaleX = videoRect.width / actualCanvasWidth;
    const scaleY = videoRect.height / actualCanvasHeight;
    
    // Set canvas size to match video element display size
    overlay.width = videoRect.width;
    overlay.height = videoRect.height;
    
    const ctx = overlay.getContext('2d');
    ctx.clearRect(0, 0, overlay.width, overlay.height);

    // V·∫Ω bounding boxes t·ª´ activeTracks (ho·∫∑c lastDetections n·∫øu ch∆∞a c√≥ tracks)
    const tracksToDraw = Array.from(activeTracks.values()).length > 0 
      ? Array.from(activeTracks.values())
      : lastDetections;
    
    if (tracksToDraw.length > 0) {
      tracksToDraw.forEach(track => {
        // ƒê·ªçc bbox t·ª´ API format: bbox l√† m·∫£ng [x1, y1, x2, y2]
        const bbox = track.bbox || [];
        if (bbox.length < 4) return;
        
        const [x1, y1, x2, y2] = bbox;
        const className = track.class || '';
        const confidence = track.confidence || 0;
        const trackId = track.track_id || track.id || '?';
        const isNew = track.is_new || false;
        
        // Scale coordinates t·ª´ video stream size sang display size
        let scaledX1 = x1 * scaleX;
        let scaledY1 = y1 * scaleY;
        let scaledX2 = x2 * scaleX;
        let scaledY2 = y2 * scaleY;
        
        // V√¨ video c√≥ transform: scaleX(-1) (mirror), c·∫ßn ƒë·∫£o ng∆∞·ª£c t·ªça ƒë·ªô X
        // ƒë·ªÉ bounding boxes hi·ªÉn th·ªã ƒë√∫ng v·ªã tr√≠
        const canvasWidth = overlay.width;
        const tempX1 = scaledX1;
        scaledX1 = canvasWidth - scaledX2;
        scaledX2 = canvasWidth - tempX1;
        
        const scaledWidth = scaledX2 - scaledX1;
        const scaledHeight = scaledY2 - scaledY1;
        
        // M√†u s·∫Øc d·ª±a tr√™n is_new v√† confidence
        let color;
        if (isNew) {
          color = 'rgba(34, 197, 94, 0.9)'; // Bright green for new tracks
        } else if (confidence > 0.7) {
          color = 'rgba(59, 130, 246, 0.9)'; // Blue for high confidence
        } else if (confidence > 0.5) {
          color = 'rgba(251, 191, 36, 0.9)'; // Yellow for medium
        } else {
          color = 'rgba(239, 68, 68, 0.9)'; // Red for low
        }
        
        // V·∫Ω bounding box
        ctx.strokeStyle = color;
        ctx.lineWidth = 3;
        ctx.strokeRect(scaledX1, scaledY1, scaledWidth, scaledHeight);
        
        // V·∫Ω background cho label v·ªõi track ID
        let label = `ID:${trackId} ${capitalizeFirst(translateClass(className))} ${Math.round(confidence * 100)}%`;
        if (isNew) {
          label = `NEW ${label}`;
        }
        ctx.font = 'bold 14px Arial';
        const textMetrics = ctx.measureText(label);
        const textWidth = textMetrics.width;
        const textHeight = 18;
        
        // ƒê·∫£m b·∫£o label kh√¥ng b·ªã v∆∞·ª£t qu√° canvas
        const labelX = Math.max(0, Math.min(scaledX1, overlay.width - textWidth - 8));
        const labelY = Math.max(textHeight + 4, scaledY1);
        
        ctx.fillStyle = color;
        ctx.fillRect(labelX, labelY - textHeight - 4, textWidth + 8, textHeight);
        
        // V·∫Ω text
        ctx.fillStyle = 'white';
        ctx.fillText(label, labelX + 4, labelY - 6);
      });
    }
  }, [lastDetections, activeTracks]);

  // Effect ƒë·ªÉ v·∫Ω bounding boxes khi detections thay ƒë·ªïi
  useEffect(() => {
    drawBoundingBoxes();
  }, [drawBoundingBoxes]);

  // Effect ƒë·ªÉ resize canvas khi video resize
  useEffect(() => {
    if (!videoRef.current || !isStreaming) return;

    const video = videoRef.current;
    const handleResize = () => {
      drawBoundingBoxes();
    };

    // Listen for video loadedmetadata
    video.addEventListener('loadedmetadata', handleResize);
    // Listen for window resize
    window.addEventListener('resize', handleResize);

    return () => {
      video.removeEventListener('loadedmetadata', handleResize);
      window.removeEventListener('resize', handleResize);
    };
  }, [isStreaming, drawBoundingBoxes]);

  if (!isActive) {
    return null;
  }

  return (
    <div className="fixed inset-0 bg-gradient-to-br from-gray-900 via-black to-gray-900 z-50 flex flex-col">
      {/* Header - C·∫£i thi·ªán v·ªõi gradient */}
      <div className="bg-gradient-to-r from-blue-600 via-indigo-600 to-purple-600 shadow-2xl border-b-4 border-blue-500">
        <div className="container mx-auto px-4 sm:px-6 py-4">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-4">
              <div className="w-12 h-12 bg-white bg-opacity-20 backdrop-blur-sm rounded-xl flex items-center justify-center shadow-lg border-2 border-white border-opacity-30">
                <span className="text-2xl">üìπ</span>
              </div>
              <div>
                <h2 className="text-xl sm:text-2xl font-extrabold text-white drop-shadow-lg">
                  {t('Camera Mode')}
                </h2>
                <p className="text-sm text-blue-100 font-medium mt-1">
                  {isStreaming ? (
                    <span className="flex items-center gap-2 flex-wrap">
                      <span className="w-2 h-2 bg-green-300 rounded-full animate-pulse"></span>
                      {t('Streaming')} ‚Ä¢ {t('Frame')}: <span className="font-bold">{frameCount}</span>
                      {fps > 0 && <span>‚Ä¢ FPS: <span className="font-bold">{fps}</span></span>}
                      {detectionRate > 0 && <span>‚Ä¢ Rate: <span className="font-bold">{detectionRate}/s</span></span>}
                    </span>
                  ) : (
                    <span className="flex items-center gap-2">
                      <span className="w-2 h-2 bg-yellow-300 rounded-full animate-pulse"></span>
                      {t('Initializing...')}
                    </span>
                  )}
                </p>
              </div>
            </div>
            <button
              onClick={onClose}
              className="px-6 py-3 bg-gradient-to-r from-red-600 to-red-700 hover:from-red-700 hover:to-red-800 text-white rounded-xl font-bold shadow-xl hover:shadow-2xl transition-all duration-300 flex items-center gap-2 transform hover:scale-105 active:scale-95 border-2 border-white border-opacity-30"
            >
              <span>‚úï</span>
              <span className="hidden sm:inline">{t('Close')}</span>
            </button>
          </div>
        </div>
      </div>

      {/* Main Content - Two Column Layout gi·ªëng Image mode */}
      <div className="flex-1 overflow-y-auto bg-gradient-to-br from-gray-50 via-blue-50 to-indigo-50">
        <div className="container mx-auto px-4 sm:px-6 py-4 sm:py-6 h-full">
          {error && (
            <div className="mb-4 bg-gradient-to-r from-red-600 to-red-700 text-white p-4 rounded-2xl shadow-2xl border-2 border-red-400">
              <div className="flex items-center gap-3">
                <div className="w-10 h-10 bg-white bg-opacity-20 rounded-full flex items-center justify-center flex-shrink-0">
                  <span className="text-xl">‚ö†Ô∏è</span>
                </div>
                <p className="font-bold text-base">{error}</p>
              </div>
            </div>
          )}

          {/* Grid Layout: 2 c·ªôt tr√™n desktop, 1 c·ªôt tr√™n mobile */}
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-4 sm:gap-6 h-full">
            {/* Left Column: Video Feed (2/3 width tr√™n desktop) */}
            <div className="lg:col-span-2 flex flex-col">
              <div className="relative w-full h-full min-h-[400px] bg-black rounded-2xl overflow-hidden shadow-2xl border-4 border-white border-opacity-30 flex items-center justify-center">
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  className="w-full h-full object-contain"
                  style={{ transform: 'scaleX(-1)' }} // Mirror effect
                />
          
                {/* Overlay canvas for bounding boxes */}
                <canvas
                  ref={overlayCanvasRef}
                  className="absolute top-0 left-0 pointer-events-none"
                  style={{ 
                    width: '100%',
                    height: '100%'
                  }}
                />
                
                {/* Detection indicator - Nh·ªè g·ªçn, kh√¥ng che video */}
                {isDetecting && (
                  <div className="absolute top-4 left-4 bg-gradient-to-r from-blue-600 to-indigo-600 text-white px-4 py-2 rounded-full font-bold shadow-2xl border-2 border-white backdrop-blur-sm flex items-center gap-2 z-20">
                    <div className="relative w-4 h-4">
                      <div className="absolute inset-0 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                    </div>
                    <span className="text-sm">{t('Detecting...')}</span>
                  </div>
                )}

                {/* Detection count badge - C·∫£i thi·ªán */}
                {lastDetections.length > 0 && (
                  <div className="absolute top-4 right-4 bg-gradient-to-r from-green-500 to-emerald-600 text-white px-4 py-2 rounded-full font-extrabold shadow-2xl border-2 border-white backdrop-blur-sm">
                    <div className="flex items-center gap-2">
                      <span className="text-lg">üéØ</span>
                      <span>{lastDetections.length} {t('objects')}</span>
                    </div>
                  </div>
                )}
              </div>

              {/* Hidden canvas for frame capture */}
              <canvas ref={canvasRef} className="hidden" />
            </div>

            {/* Right Column: Results Table (1/3 width tr√™n desktop) */}
            <div className="lg:col-span-1">
              <div className="bg-white rounded-2xl shadow-xl border-2 border-gray-200 p-5 sm:p-6 h-full overflow-y-auto">
                {activeTracks.size > 0 || lastDetections.length > 0 ? (
                  <ResultsTable detections={Array.from(activeTracks.values()).length > 0 
                    ? Array.from(activeTracks.values()).map(t => ({
                        id: t.track_id || t.id,
                        class: t.class,
                        class_id: t.class_id,
                        confidence: t.confidence,
                        bbox: t.bbox,
                        width: t.bbox ? t.bbox[2] - t.bbox[0] : 0,
                        height: t.bbox ? t.bbox[3] - t.bbox[1] : 0
                      }))
                    : lastDetections} />
                ) : (
                  <div className="text-center py-8">
                    <div className="w-20 h-20 bg-gradient-to-br from-gray-200 to-gray-300 rounded-2xl flex items-center justify-center mx-auto mb-4 shadow-md">
                      <span className="text-5xl">üîç</span>
                    </div>
                    <p className="text-base font-bold text-gray-700 mb-2">{t('No objects detected')}</p>
                    <p className="text-sm text-gray-500">{t('Waiting for detection...')}</p>
                  </div>
                )}
              </div>
            </div>
          </div>
        </div>
      </div>

      {/* Controls - Tr·∫°ng th√°i + ƒëi·ªÅu khi·ªÉn audio */}
      <div className="bg-gradient-to-r from-gray-800 via-gray-900 to-gray-800 border-t-4 border-blue-500 shadow-2xl">
        <div className="container mx-auto px-4 sm:px-6 py-5">
          <div className="flex flex-col sm:flex-row items-center justify-between gap-4">
            {/* Status Indicator */}
            <div className="flex items-center gap-3 bg-white bg-opacity-10 backdrop-blur-sm rounded-xl px-5 py-3 border-2 border-white border-opacity-20">
              <div className="w-10 h-10 bg-gradient-to-br from-blue-500 to-purple-600 rounded-lg flex items-center justify-center shadow-lg">
                <span className="text-xl">üìä</span>
              </div>
              <div>
                <div className="text-xs text-gray-300 mb-1 font-medium">{t('Status')}</div>
                {isStreaming ? (
                  <div className="flex items-center gap-2">
                    <span className="w-3 h-3 bg-green-400 rounded-full animate-pulse shadow-lg"></span>
                    <span className="text-white font-bold">{t('Active')}</span>
                  </div>
                ) : (
                  <div className="flex items-center gap-2">
                    <span className="w-3 h-3 bg-gray-400 rounded-full"></span>
                    <span className="text-gray-400 font-bold">{t('Inactive')}</span>
                  </div>
                )}
              </div>
            </div>

            {/* Audio Controls */}
            <div className="flex items-center gap-3 bg-white bg-opacity-10 backdrop-blur-sm rounded-xl px-5 py-3 border-2 border-white border-opacity-20">
              <button
                type="button"
                onClick={handleToggleAudio}
                className={`flex items-center gap-2 px-4 py-2 rounded-lg font-bold shadow-md transition-all ${
                  isAudioEnabled
                    ? 'bg-green-500 hover:bg-green-600 text-white'
                    : 'bg-gray-600 hover:bg-gray-700 text-gray-200'
                }`}
              >
                <span className="text-lg">{isAudioEnabled ? 'üîä' : 'üîá'}</span>
                <span>{isAudioEnabled ? t('Audio On') : t('Audio Off')}</span>
              </button>

              <button
                type="button"
                onClick={handleRepeatAudio}
                disabled={!lastAnnouncedDetectionsRef.current || !isAudioEnabled}
                className={`flex items-center gap-2 px-4 py-2 rounded-lg font-bold shadow-md transition-all ${
                  !lastAnnouncedDetectionsRef.current || !isAudioEnabled
                    ? 'bg-gray-500 text-gray-200 cursor-not-allowed'
                    : 'bg-blue-500 hover:bg-blue-600 text-white'
                }`}
              >
                <span className="text-lg">üîÅ</span>
                <span>{t('Repeat')}</span>
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default CameraView;

