"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SCRIPT 1: DATA PREPROCESSING - HOÃ€N CHá»ˆNH
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Má»¤C TIÃŠU: Xá»­ lÃ½ COCO 2014 thÃ nh dataset cÃ¢n báº±ng cho YOLO
INPUT:  82k train + 40k val (80 classes, imbalanced)
OUTPUT: 20k train + 18k val (80 classes, balanced 250/class)

FEATURES:
âœ… Smart sampling (quality score)
âœ… Augmentation cho classes thiáº¿u
âœ… Validation processing
âœ… Format YOLO chuáº©n
âœ… Error handling & cleanup

THá»œI GIAN: ~90-120 phÃºt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import os
import glob
import shutil
import pickle
import json
import cv2
import numpy as np
import random
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict, Counter

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Cáº¤U HÃŒNH
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DATASET_PATH = "/kaggle/input/coco-2014-dataset-for-yolov3/coco2014"
OUTPUT_DIR = "/kaggle/working/yolo_balanced_data"
TARGET_PER_CLASS = 250

print("="*80)
print("ğŸš€ DATA PREPROCESSING PIPELINE")
print("="*80)
print(f"Input:  {DATASET_PATH}")
print(f"Output: {OUTPUT_DIR}")
print(f"Target: {TARGET_PER_CLASS} images/class")
print("="*80)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 1: PHÃ‚N TÃCH DATASET
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "â”"*80)
print("ğŸ“Š BÆ¯á»šC 1/6: PHÃ‚N TÃCH DATASET")
print("â”"*80)

# Load classes
with open(os.path.join(DATASET_PATH, "coco.names"), 'r') as f:
    class_names = [line.strip() for line in f.readlines()]

print(f"âœ“ Classes: {len(class_names)}")

# Scan labels
train_labels = glob.glob(os.path.join(DATASET_PATH, "labels/train2014/*.txt"))
val_labels = glob.glob(os.path.join(DATASET_PATH, "labels/val2014/*.txt"))

train_class_to_images = defaultdict(list)
train_image_class_count = defaultdict(set)

print(f"â³ Scanning {len(train_labels):,} training labels...")

for label_file in tqdm(train_labels, desc="Analyzing"):
    image_name = os.path.basename(label_file).replace('.txt', '.jpg')
    image_path = os.path.join(DATASET_PATH, "images/train2014", image_name)
    
    with open(label_file, 'r') as f:
        lines = f.readlines()
    
    classes_in_image = set()
    for line in lines:
        if line.strip():
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                bbox = [float(x) for x in parts[1:5]]
                
                train_class_to_images[class_id].append({
                    'image_path': image_path,
                    'label_path': label_file,
                    'bbox': bbox,
                    'image_name': image_name
                })
                classes_in_image.add(class_id)
    
    for cls in classes_in_image:
        train_image_class_count[image_name].update(classes_in_image)

# Statistics
class_stats = []
classes_enough = []
classes_deficit = []

for class_id in range(80):
    num_images = len(set([item['image_name'] for item in train_class_to_images[class_id]]))
    class_stats.append({'class_id': class_id, 'num_images': num_images})
    
    if num_images >= TARGET_PER_CLASS:
        classes_enough.append(class_id)
    elif num_images > 0:
        classes_deficit.append(class_id)

print(f"âœ“ Classes â‰¥{TARGET_PER_CLASS}: {len(classes_enough)}")
print(f"âœ“ Classes <{TARGET_PER_CLASS}: {len(classes_deficit)}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 2: SMART SAMPLING
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "â”"*80)
print("ğŸ¯ BÆ¯á»šC 2/6: SMART SAMPLING")
print("â”"*80)

os.makedirs(os.path.join(OUTPUT_DIR, "images/train"), exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "labels/train"), exist_ok=True)

def calculate_quality_score(item, image_class_count):
    score = len(image_class_count.get(item['image_name'], set())) * 3.0
    bbox_area = item['bbox'][2] * item['bbox'][3]
    
    if 0.05 <= bbox_area <= 0.6:
        score += 2.0
    elif 0.01 <= bbox_area < 0.05:
        score += 1.0
    
    x, y = item['bbox'][0], item['bbox'][1]
    if 0.2 <= x <= 0.8 and 0.2 <= y <= 0.8:
        score += 1.0
    
    return score

selected_images = defaultdict(list)

# Sample classes â‰¥250
for class_id in tqdm(classes_enough, desc="Sampling"):
    items = train_class_to_images[class_id]
    
    scored_items = []
    seen = set()
    
    for item in items:
        if item['image_name'] not in seen:
            score = calculate_quality_score(item, train_image_class_count)
            scored_items.append({'item': item, 'score': score})
            seen.add(item['image_name'])
    
    scored_items.sort(key=lambda x: x['score'], reverse=True)
    selected_images[class_id] = [x['item'] for x in scored_items[:TARGET_PER_CLASS]]

# Keep all for deficit classes
for class_id in classes_deficit:
    items = train_class_to_images[class_id]
    seen = {}
    for item in items:
        if item['image_name'] not in seen:
            seen[item['image_name']] = item
    selected_images[class_id] = list(seen.values())

# Copy files
images_to_copy = set()
for class_id in range(80):
    if class_id in selected_images:
        for item in selected_images[class_id]:
            images_to_copy.add(item['image_name'])

print(f"ğŸ“ Copying {len(images_to_copy):,} images...")

for image_name in tqdm(images_to_copy, desc="Copying"):
    src_img = os.path.join(DATASET_PATH, "images/train2014", image_name)
    dst_img = os.path.join(OUTPUT_DIR, "images/train", image_name)
    shutil.copy2(src_img, dst_img)
    
    label_name = image_name.replace('.jpg', '.txt')
    src_lbl = os.path.join(DATASET_PATH, "labels/train2014", label_name)
    dst_lbl = os.path.join(OUTPUT_DIR, "labels/train", label_name)
    shutil.copy2(src_lbl, dst_lbl)

print(f"âœ“ Copied {len(images_to_copy):,} files")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 3: AUGMENTATION
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "â”"*80)
print("ğŸ¨ BÆ¯á»šC 3/6: AUGMENTATION")
print("â”"*80)

def augment_image(image, bboxes):
    aug_image = image.copy()
    aug_bboxes = bboxes.copy()
    
    # Flip
    if random.random() > 0.5:
        aug_image = cv2.flip(aug_image, 1)
        for i in range(len(aug_bboxes)):
            aug_bboxes[i][0] = 1.0 - aug_bboxes[i][0]
    
    # Brightness
    aug_image = np.clip(aug_image * random.uniform(0.85, 1.15), 0, 255).astype(np.uint8)
    
    # Validate bboxes
    valid_bboxes = []
    for bbox in aug_bboxes:
        x, y, w, h = bbox[1:5]
        x = np.clip(x, 0, 1)
        y = np.clip(y, 0, 1)
        w = np.clip(w, 0, 1)
        h = np.clip(h, 0, 1)
        
        if w > 0.01 and h > 0.01:
            valid_bboxes.append([bbox[0], x, y, w, h])
    
    return aug_image, np.array(valid_bboxes) if valid_bboxes else aug_bboxes

def read_yolo_label(path):
    bboxes = []
    with open(path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                bboxes.append([int(parts[0])] + [float(x) for x in parts[1:5]])
    return np.array(bboxes) if bboxes else np.array([]).reshape(0, 5)

def write_yolo_label(path, bboxes):
    with open(path, 'w') as f:
        for bbox in bboxes:
            f.write(f"{int(bbox[0])} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f} {bbox[4]:.6f}\n")

total_augmented = 0

for class_id in tqdm(classes_deficit, desc="Augmenting"):
    current = len(set([item['image_name'] for item in selected_images[class_id]]))
    need = TARGET_PER_CLASS - current
    
    if need <= 0:
        continue
    
    source_images = list(set([item['image_name'] for item in selected_images[class_id]]))
    
    for i in range(need):
        src_name = random.choice(source_images)
        src_img = os.path.join(OUTPUT_DIR, "images/train", src_name)
        src_lbl = os.path.join(OUTPUT_DIR, "labels/train", src_name.replace('.jpg', '.txt'))
        
        image = cv2.imread(src_img)
        if image is None:
            continue
        
        bboxes = read_yolo_label(src_lbl)
        if len(bboxes) == 0:
            continue
        
        aug_img, aug_bboxes = augment_image(image, bboxes)
        
        aug_name = f"{src_name.replace('.jpg', '')}_aug{i}.jpg"
        aug_img_path = os.path.join(OUTPUT_DIR, "images/train", aug_name)
        aug_lbl_path = os.path.join(OUTPUT_DIR, "labels/train", aug_name.replace('.jpg', '.txt'))
        
        cv2.imwrite(aug_img_path, aug_img)
        write_yolo_label(aug_lbl_path, aug_bboxes)
        
        total_augmented += 1

print(f"âœ“ Augmented {total_augmented:,} images")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 4: VALIDATION PROCESSING
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "â”"*80)
print("ğŸ“¦ BÆ¯á»šC 4/6: VALIDATION SET")
print("â”"*80)

os.makedirs(os.path.join(OUTPUT_DIR, "images/val"), exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "labels/val"), exist_ok=True)

val_class_to_images = defaultdict(list)

for label_file in tqdm(val_labels[:10000], desc="Scanning val"):  # Limit to save time
    image_name = os.path.basename(label_file).replace('.txt', '.jpg')
    image_path = os.path.join(DATASET_PATH, "images/val2014", image_name)
    
    with open(label_file, 'r') as f:
        for line in f:
            if line.strip():
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    val_class_to_images[class_id].append({
                        'image_path': image_path,
                        'label_path': label_file,
                        'image_name': image_name
                    })

# Sample validation
val_images_to_copy = set()

for class_id in range(80):
    items = val_class_to_images.get(class_id, [])
    unique = {}
    for item in items:
        if item['image_name'] not in unique:
            unique[item['image_name']] = item
    
    selected = random.sample(list(unique.values()), min(len(unique), TARGET_PER_CLASS))
    for item in selected:
        val_images_to_copy.add(item['image_name'])

print(f"ğŸ“ Copying {len(val_images_to_copy):,} validation images...")

for image_name in tqdm(val_images_to_copy, desc="Copying val"):
    src_img = os.path.join(DATASET_PATH, "images/val2014", image_name)
    dst_img = os.path.join(OUTPUT_DIR, "images/val", image_name)
    shutil.copy2(src_img, dst_img)
    
    label_name = image_name.replace('.jpg', '.txt')
    src_lbl = os.path.join(DATASET_PATH, "labels/val2014", label_name)
    dst_lbl = os.path.join(OUTPUT_DIR, "labels/val", label_name)
    shutil.copy2(src_lbl, dst_lbl)

print(f"âœ“ Copied {len(val_images_to_copy):,} validation files")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 5: CREATE CONFIG
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "â”"*80)
print("âš™ï¸  BÆ¯á»šC 5/6: CREATE CONFIG")
print("â”"*80)

import yaml

data_yaml = {
    'path': OUTPUT_DIR,
    'train': 'images/train',
    'val': 'images/val',
    'nc': 80,
    'names': {i: name for i, name in enumerate(class_names)}
}

yaml_path = os.path.join(OUTPUT_DIR, "data.yaml")
with open(yaml_path, 'w') as f:
    yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)

print(f"âœ“ Created: {yaml_path}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BÆ¯á»šC 6: FINAL SUMMARY
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

print("\n" + "="*80)
print("ğŸ‰ PREPROCESSING HOÃ€N THÃ€NH!")
print("="*80)

train_imgs = len(os.listdir(os.path.join(OUTPUT_DIR, "images/train")))
val_imgs = len(os.listdir(os.path.join(OUTPUT_DIR, "images/val")))

print(f"""
ğŸ“Š SUMMARY:
  â€¢ Training images:   {train_imgs:,}
  â€¢ Validation images: {val_imgs:,}
  â€¢ Classes:           80
  â€¢ Target/class:      {TARGET_PER_CLASS}
  â€¢ Augmented:         {total_augmented:,}

ğŸ“ OUTPUT:
  â€¢ Dataset: {OUTPUT_DIR}
  â€¢ Config:  {yaml_path}

âœ… Sáº´N SÃ€NG CHO TRAINING!
""")

print("="*80)