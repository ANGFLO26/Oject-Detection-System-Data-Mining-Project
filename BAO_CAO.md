# B√ÅO C√ÅO ƒê·ªí √ÅN
## H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN ƒê·ªêI T·ª¢NG S·ª¨ D·ª§NG YOLOv8 V·ªöI DEEP SORT TRACKING

**Sinh vi√™n:** Phan VƒÉn T√†i - MSSV: 2202081  
**Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n:** Ti·∫øn sƒ© Tr·∫ßn Ng·ªçc Anh  
**Tr∆∞·ªùng ƒê·∫°i h·ªçc T√¢n T·∫°o - Khoa C√¥ng ngh·ªá Th√¥ng tin**

---

## M·ª§C L·ª§C

1. [T√≥m t·∫Øt (Abstract)](#1-t√≥m-t·∫Øt-abstract)
2. [Gi·ªõi thi·ªáu ƒë·ªÅ t√†i](#2-gi·ªõi-thi·ªáu-ƒë·ªÅ-t√†i)
3. [C∆° s·ªü l√Ω thuy·∫øt](#3-c∆°-s·ªü-l√Ω-thuy·∫øt)
4. [Ph√¢n t√≠ch y√™u c·∫ßu](#4-ph√¢n-t√≠ch-y√™u-c·∫ßu)
5. [Thi·∫øt k·∫ø h·ªá th·ªëng](#5-thi·∫øt-k·∫ø-h·ªá-th·ªëng)
6. [Chu·∫©n b·ªã d·ªØ li·ªáu](#6-chu·∫©n-b·ªã-d·ªØ-li·ªáu)
7. [Hu·∫•n luy·ªán m√¥ h√¨nh](#7-hu·∫•n-luy·ªán-m√¥-h√¨nh)
8. [K·∫øt qu·∫£](#8-k·∫øt-qu·∫£)
9. [Demo / ·ª®ng d·ª•ng](#9-demo--·ª©ng-d·ª•ng)
10. [ƒê√°nh gi√° & Th·∫£o lu·∫≠n](#10-ƒë√°nh-gi√°--th·∫£o-lu·∫≠n)
11. [K·∫øt lu·∫≠n & H∆∞·ªõng ph√°t tri·ªÉn](#11-k·∫øt-lu·∫≠n--h∆∞·ªõng-ph√°t-tri·ªÉn)
12. [T√†i li·ªáu tham kh·∫£o](#12-t√†i-li·ªáu-tham-kh·∫£o)

---

## 1. T√ìM T·∫ÆT (ABSTRACT)

H·ªá th·ªëng nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng real-time l√† m·ªôt ·ª©ng d·ª•ng quan tr·ªçng trong nhi·ªÅu lƒ©nh v·ª±c nh∆∞ gi√°m s√°t an ninh, h·ªó tr·ª£ ng∆∞·ªùi khi·∫øm th·ªã, v√† t·ª± ƒë·ªông h√≥a. Tuy nhi√™n, vi·ªác x√¢y d·ª±ng m·ªôt h·ªá th·ªëng hi·ªáu qu·∫£ ƒë√≤i h·ªèi gi·∫£i quy·∫øt nhi·ªÅu th√°ch th·ª©c, ƒë·∫∑c bi·ªát l√† v·∫•n ƒë·ªÅ m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu (data imbalance) trong c√°c dataset ph·ªï bi·∫øn nh∆∞ COCO.

Nghi√™n c·ª©u n√†y tr√¨nh b√†y m·ªôt pipeline ho√†n ch·ªânh ƒë·ªÉ x·ª≠ l√Ω v√† c√¢n b·∫±ng dataset COCO 2014, t·ª´ 82,081 ·∫£nh training ban ƒë·∫ßu xu·ªëng c√≤n 10,030 ·∫£nh ƒë∆∞·ª£c ch·ªçn l·ªçc th√¥ng qua thu·∫≠t to√°n smart sampling d·ª±a tr√™n quality score. Dataset sau x·ª≠ l√Ω ƒë·∫°t ƒë∆∞·ª£c s·ª± c√¢n b·∫±ng v·ªõi kho·∫£ng 250 ·∫£nh cho m·ªói class trong 80 classes, gi·∫£m t·ª∑ l·ªá imbalance t·ª´ 321:1 xu·ªëng c√≤n ~1:1.

H·ªá th·ªëng ƒë∆∞·ª£c x√¢y d·ª±ng s·ª≠ d·ª•ng YOLOv8s (Small variant) v·ªõi 11.2 tri·ªáu tham s·ªë v√† 28.8 GFLOPs, ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n GPU Tesla P100 v·ªõi 17GB VRAM trong 120 epochs, m·∫•t kho·∫£ng 8 gi·ªù. M√¥ h√¨nh ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·∫∑c bi·ªát cho GPU P100 v·ªõi batch size 28, 20 workers cho data loading, v√† Mixed Precision Training (AMP) ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô hu·∫•n luy·ªán.

K·∫øt qu·∫£ th·ª±c nghi·ªám cho th·∫•y m√¥ h√¨nh ƒë·∫°t ƒë∆∞·ª£c mAP50 = 66.01%, Precision = 72.83%, Recall = 59.33%, v√† F1-Score = 65.40% tr√™n validation set g·ªìm 9,217 ·∫£nh. M·∫∑c d√π k·∫øt qu·∫£ n√†y th·∫•p h∆°n baseline (69.25%) kho·∫£ng 4.7%, nghi√™n c·ª©u ƒë√£ ph√¢n t√≠ch v√† ƒë∆∞a ra c√°c nguy√™n nh√¢n c√≥ th·ªÉ nh∆∞ model qu√° l·ªõn so v·ªõi dataset size, d·∫´n ƒë·∫øn overfitting ti·ªÅm ·∫©n.

H·ªá th·ªëng web application ƒë∆∞·ª£c ph√°t tri·ªÉn v·ªõi ki·∫øn tr√∫c Frontend (React) v√† Backend (FastAPI), t√≠ch h·ª£p DeepSORT tracking ƒë·ªÉ duy tr√¨ track IDs ·ªïn ƒë·ªãnh qua c√°c frames. ƒê·∫∑c bi·ªát, h·ªá th·ªëng h·ªó tr·ª£ Text-to-Speech b·∫±ng ti·∫øng Vi·ªát, gom k·∫øt qu·∫£ theo l·ªõp (v√≠ d·ª•: "Ph√°t hi·ªán 2 xe t·∫£i. Ph√°t hi·ªán 1 ng∆∞·ªùi"), h·ªØu √≠ch cho ng∆∞·ªùi khi·∫øm th·ªã.

Nghi√™n c·ª©u ƒë√≥ng g√≥p m·ªôt pipeline x·ª≠ l√Ω d·ªØ li·ªáu th√¥ng minh v·ªõi quality scoring, ph∆∞∆°ng ph√°p t·ªëi ∆∞u h√≥a training cho GPU P100, v√† m·ªôt h·ªá th·ªëng ·ª©ng d·ª•ng ho√†n ch·ªânh v·ªõi t√≠nh nƒÉng accessibility. K·∫øt qu·∫£ nghi√™n c·ª©u cung c·∫•p insights quan tr·ªçng v·ªÅ m·ªëi quan h·ªá gi·ªØa model size v√† dataset size, g·ª£i √Ω r·∫±ng YOLOv8n (nano variant) c√≥ th·ªÉ ph√π h·ª£p h∆°n cho dataset 10k ·∫£nh.

**T·ª´ kh√≥a:** Object Detection, YOLOv8, DeepSORT, Data Imbalance, Smart Sampling, Real-time Tracking, Web Application

---

## 2. GI·ªöI THI·ªÜU ƒê·ªÄ T√ÄI

### 2.1. B·ªëi c·∫£nh v√† ƒë·ªông l·ª±c

Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng (Object Detection) l√† m·ªôt trong nh·ªØng b√†i to√°n c∆° b·∫£n v√† quan tr·ªçng nh·∫•t trong lƒ©nh v·ª±c Computer Vision. Kh√°c v·ªõi b√†i to√°n ph√¢n lo·∫°i ·∫£nh (Image Classification), object detection kh√¥ng ch·ªâ x√°c ƒë·ªãnh xem ƒë·ªëi t∆∞·ª£ng n√†o c√≥ trong ·∫£nh m√† c√≤n ph·∫£i x√°c ƒë·ªãnh ch√≠nh x√°c v·ªã tr√≠ c·ªßa ch√∫ng th√¥ng qua c√°c bounding boxes. ·ª®ng d·ª•ng c·ªßa object detection r·∫•t ƒëa d·∫°ng, t·ª´ gi√°m s√°t an ninh, t·ª± ƒë·ªông h√≥a giao th√¥ng, h·ªó tr·ª£ ng∆∞·ªùi khi·∫øm th·ªã, ƒë·∫øn c√°c h·ªá th·ªëng robot v√† xe t·ª± l√°i.

Trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y, c√°c m√¥ h√¨nh deep learning, ƒë·∫∑c bi·ªát l√† YOLO (You Only Look Once) series, ƒë√£ ƒë·∫°t ƒë∆∞·ª£c nh·ªØng th√†nh t·ª±u ƒë√°ng k·ªÉ trong vi·ªác nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng real-time. YOLOv8, phi√™n b·∫£n m·ªõi nh·∫•t c·ªßa series n√†y, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Ultralytics, mang l·∫°i hi·ªáu su·∫•t cao v·ªõi t·ªëc ƒë·ªô x·ª≠ l√Ω nhanh, ph√π h·ª£p cho c√°c ·ª©ng d·ª•ng th·ªùi gian th·ª±c.

Tuy nhi√™n, vi·ªác hu·∫•n luy·ªán c√°c m√¥ h√¨nh object detection hi·ªáu qu·∫£ ƒë√≤i h·ªèi dataset ch·∫•t l∆∞·ª£ng cao v√† c√¢n b·∫±ng. Dataset COCO (Common Objects in Context) l√† m·ªôt trong nh·ªØng dataset ph·ªï bi·∫øn nh·∫•t, nh∆∞ng n√≥ c√≥ v·∫•n ƒë·ªÅ m·∫•t c√¢n b·∫±ng nghi√™m tr·ªçng gi·ªØa c√°c classes. V√≠ d·ª•, class "person" c√≥ h∆°n 7,000 ·∫£nh trong khi class "toaster" ch·ªâ c√≥ kho·∫£ng 25 ·∫£nh, t·∫°o ra t·ª∑ l·ªá imbalance l√™n ƒë·∫øn 321:1. S·ª± m·∫•t c√¢n b·∫±ng n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn vi·ªác model h·ªçc t·ªët c√°c classes ph·ªï bi·∫øn nh∆∞ng k√©m hi·ªáu qu·∫£ v·ªõi c√°c classes hi·∫øm.

Ngo√†i ra, vi·ªác x√¢y d·ª±ng m·ªôt h·ªá th·ªëng ·ª©ng d·ª•ng ho√†n ch·ªânh v·ªõi kh·∫£ nƒÉng tracking ƒë·ªëi t∆∞·ª£ng qua nhi·ªÅu frames v√† h·ªó tr·ª£ ng∆∞·ªùi d√πng khi·∫øm th·ªã l√† m·ªôt th√°ch th·ª©c k·ªπ thu·∫≠t quan tr·ªçng. DeepSORT (Deep Simple Online and Realtime Tracking) l√† m·ªôt gi·∫£i ph√°p ph·ªï bi·∫øn cho b√†i to√°n multi-object tracking, k·∫øt h·ª£p Kalman Filter v√† feature matching ƒë·ªÉ duy tr√¨ track IDs ·ªïn ƒë·ªãnh.

### 2.2. M·ª•c ti√™u nghi√™n c·ª©u

Nghi√™n c·ª©u n√†y ƒë·∫∑t ra c√°c m·ª•c ti√™u ch√≠nh sau:

1. **X√¢y d·ª±ng pipeline x·ª≠ l√Ω d·ªØ li·ªáu th√¥ng minh**: Ph√°t tri·ªÉn m·ªôt h·ªá th·ªëng t·ª± ƒë·ªông ƒë·ªÉ chuy·ªÉn ƒë·ªïi dataset COCO 2014 t·ª´ tr·∫°ng th√°i m·∫•t c√¢n b·∫±ng (321:1) sang tr·∫°ng th√°i c√¢n b·∫±ng (~1:1) th√¥ng qua thu·∫≠t to√°n smart sampling d·ª±a tr√™n quality score.

2. **Hu·∫•n luy·ªán m√¥ h√¨nh YOLOv8 hi·ªáu qu·∫£**: T·ªëi ∆∞u h√≥a qu√° tr√¨nh training YOLOv8s tr√™n balanced dataset, ƒë·∫∑c bi·ªát t·ªëi ∆∞u cho GPU Tesla P100 v·ªõi 17GB VRAM, ƒë·∫°t ƒë∆∞·ª£c mAP50 m·ª•c ti√™u k·ª≥ v·ªçng t·ª´ 0.78-0.83 (m·ª•c ti√™u t·ªëi thi·ªÉu ‚â• 0.75). *L∆∞u √Ω: K·∫øt qu·∫£ th·ª±c t·∫ø ƒë·∫°t mAP50 = 0.6601, th·∫•p h∆°n m·ª•c ti√™u k·ª≥ v·ªçng, s·∫Ω ƒë∆∞·ª£c ph√¢n t√≠ch chi ti·∫øt trong ph·∫ßn ƒë√°nh gi√°.*

3. **X√¢y d·ª±ng h·ªá th·ªëng web application**: Ph√°t tri·ªÉn m·ªôt ·ª©ng d·ª•ng web ho√†n ch·ªânh v·ªõi kh·∫£ nƒÉng:
   - Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng real-time t·ª´ camera
   - Upload v√† x·ª≠ l√Ω ·∫£nh tƒ©nh
   - Tracking ƒë·ªëi t∆∞·ª£ng v·ªõi DeepSORT
   - Audio feedback b·∫±ng ti·∫øng Vi·ªát cho ng∆∞·ªùi khi·∫øm th·ªã

4. **ƒê√°nh gi√° v√† ph√¢n t√≠ch k·∫øt qu·∫£**: So s√°nh hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh tr√™n balanced dataset v·ªõi baseline, ph√¢n t√≠ch c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£, v√† ƒë∆∞a ra c√°c ƒë·ªÅ xu·∫•t c·∫£i thi·ªán.

### 2.3. Ph·∫°m vi nghi√™n c·ª©u

Nghi√™n c·ª©u n√†y t·∫≠p trung v√†o:

- **Dataset**: COCO 2014 v·ªõi 80 classes, x·ª≠ l√Ω t·ª´ 82,081 training images xu·ªëng c√≤n 10,030 images balanced
- **Model**: YOLOv8s (Small variant) v·ªõi 11.2M parameters
- **Hardware**: GPU Tesla P100-PCIE-16GB (17.06 GB VRAM)
- **Tracking**: DeepSORT v·ªõi Kalman Filter v√† histogram-based feature extraction
- **Application**: Web application v·ªõi React frontend v√† FastAPI backend

Nghi√™n c·ª©u kh√¥ng bao g·ªìm:
- C√°c m√¥ h√¨nh object detection kh√°c ngo√†i YOLOv8
- C√°c ph∆∞∆°ng ph√°p tracking kh√°c ngo√†i DeepSORT
- Mobile application ho·∫∑c edge deployment
- Video processing batch

### 2.4. C·∫•u tr√∫c b√°o c√°o

B√°o c√°o ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh 12 ch∆∞∆°ng ch√≠nh:

- **Ch∆∞∆°ng 1**: T√≥m t·∫Øt nghi√™n c·ª©u
- **Ch∆∞∆°ng 2**: Gi·ªõi thi·ªáu ƒë·ªÅ t√†i (ch∆∞∆°ng n√†y)
- **Ch∆∞∆°ng 3**: C∆° s·ªü l√Ω thuy·∫øt v·ªÅ YOLOv8, DeepSORT, v√† c√°c metrics ƒë√°nh gi√°
- **Ch∆∞∆°ng 4**: Ph√¢n t√≠ch y√™u c·∫ßu ch·ª©c nƒÉng v√† phi ch·ª©c nƒÉng
- **Ch∆∞∆°ng 5**: Thi·∫øt k·∫ø ki·∫øn tr√∫c h·ªá th·ªëng v√† l·ª±a ch·ªçn model
- **Ch∆∞∆°ng 6**: Chi ti·∫øt pipeline x·ª≠ l√Ω d·ªØ li·ªáu v√† smart sampling
- **Ch∆∞∆°ng 7**: Qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a cho P100
- **Ch∆∞∆°ng 8**: K·∫øt qu·∫£ th·ª±c nghi·ªám v√† ph√¢n t√≠ch
- **Ch∆∞∆°ng 9**: Demo h·ªá th·ªëng v√† c√°c t√≠nh nƒÉng
- **Ch∆∞∆°ng 10**: ƒê√°nh gi√°, th·∫£o lu·∫≠n v√† lessons learned
- **Ch∆∞∆°ng 11**: K·∫øt lu·∫≠n v√† h∆∞·ªõng ph√°t tri·ªÉn
- **Ch∆∞∆°ng 12**: T√†i li·ªáu tham kh·∫£o

---

## 3. C∆† S·ªû L√ù THUY·∫æT

### 3.1. Object Detection v√† YOLO

#### 3.1.1. T·ªïng quan v·ªÅ Object Detection

Object Detection l√† b√†i to√°n x√°c ƒë·ªãnh v·ªã tr√≠ v√† ph√¢n lo·∫°i c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh. Kh√°c v·ªõi Image Classification ch·ªâ tr·∫£ v·ªÅ nh√£n c·ªßa to√†n b·ªô ·∫£nh, object detection ph·∫£i:
- X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng ƒë·ªëi t∆∞·ª£ng trong ·∫£nh
- V·∫Ω bounding box cho m·ªói ƒë·ªëi t∆∞·ª£ng
- Ph√¢n lo·∫°i t·ª´ng ƒë·ªëi t∆∞·ª£ng v√†o m·ªôt trong c√°c classes

C√°c ph∆∞∆°ng ph√°p object detection truy·ªÅn th·ªëng nh∆∞ R-CNN, Fast R-CNN, Faster R-CNN s·ª≠ d·ª•ng two-stage approach: ƒë·∫ßu ti√™n t·∫°o region proposals, sau ƒë√≥ ph√¢n lo·∫°i v√† refine bounding boxes. Tuy nhi√™n, c√°c ph∆∞∆°ng ph√°p n√†y th∆∞·ªùng ch·∫≠m v√† kh√¥ng ph√π h·ª£p cho real-time applications.

#### 3.1.2. YOLO (You Only Look Once)

YOLO ƒë∆∞·ª£c gi·ªõi thi·ªáu l·∫ßn ƒë·∫ßu v√†o nƒÉm 2016 b·ªüi Redmon et al., v·ªõi √Ω t∆∞·ªüng c√°ch m·∫°ng: thay v√¨ t·∫°o region proposals, YOLO chia ·∫£nh th√†nh grid cells v√† m·ªói cell d·ª± ƒëo√°n tr·ª±c ti·∫øp bounding boxes v√† class probabilities. ƒêi·ªÅu n√†y l√†m cho YOLO nhanh h∆°n ƒë√°ng k·ªÉ so v·ªõi c√°c ph∆∞∆°ng ph√°p two-stage.

YOLO ƒë√£ tr·∫£i qua nhi·ªÅu phi√™n b·∫£n:
- **YOLOv1** (2016): Ki·∫øn tr√∫c ƒë∆°n gi·∫£n, t·ªëc ƒë·ªô cao nh∆∞ng ƒë·ªô ch√≠nh x√°c th·∫•p
- **YOLOv2/YOLO9000** (2017): C·∫£i thi·ªán accuracy v·ªõi anchor boxes
- **YOLOv3** (2018): Multi-scale detection v·ªõi 3 scales
- **YOLOv4** (2020): T·ªëi ∆∞u h√≥a ki·∫øn tr√∫c v√† training strategy
- **YOLOv5** (2020): PyTorch implementation, d·ªÖ s·ª≠ d·ª•ng
- **YOLOv8** (2023): Phi√™n b·∫£n m·ªõi nh·∫•t v·ªõi nhi·ªÅu c·∫£i ti·∫øn

#### 3.1.3. YOLOv8 Architecture

YOLOv8 ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Ultralytics v·ªõi ki·∫øn tr√∫c ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho c·∫£ accuracy v√† speed. Ki·∫øn tr√∫c ch√≠nh bao g·ªìm:

**Backbone - CSPDarknet:**
- S·ª≠ d·ª•ng Cross Stage Partial (CSP) connections ƒë·ªÉ gi·∫£m computational cost
- C2f module thay th·∫ø C3 module trong YOLOv5, c·∫£i thi·ªán gradient flow
- Efficient feature extraction v·ªõi depthwise separable convolutions

**Neck - PANet (Path Aggregation Network):**
- K·∫øt h·ª£p top-down v√† bottom-up paths ƒë·ªÉ t·∫≠n d·ª•ng c·∫£ high-level v√† low-level features
- Feature Pyramid Network (FPN) ƒë·ªÉ x·ª≠ l√Ω objects ·ªü nhi·ªÅu scales kh√°c nhau

**Head - Decoupled Head:**
- T√°ch ri√™ng classification v√† regression tasks
- Gi·∫£m conflict gi·ªØa classification v√† localization
- C·∫£i thi·ªán accuracy ƒë√°ng k·ªÉ

**Loss Functions:**
- **Box Loss**: DFL (Distribution Focal Loss) thay v√¨ IoU loss, c·∫£i thi·ªán localization accuracy
- **Class Loss**: BCE (Binary Cross Entropy) v·ªõi label smoothing
- **DFL Loss**: Gi√∫p model h·ªçc ph√¢n ph·ªëi x√°c su·∫•t c·ªßa bounding box coordinates

**Non-Maximum Suppression (NMS):**
- Lo·∫°i b·ªè c√°c detections tr√πng l·∫∑p
- IoU threshold ƒë·ªÉ quy·∫øt ƒë·ªãnh c√°c boxes n√†o ƒë∆∞·ª£c gi·ªØ l·∫°i
- M·∫∑c ƒë·ªãnh IoU threshold = 0.45

#### 3.1.4. YOLOv8 Variants v√† So s√°nh

YOLOv8 c√≥ 5 variants v·ªõi k√≠ch th∆∞·ªõc v√† ƒë·ªô ph·ª©c t·∫°p kh√°c nhau:

| Variant | Parameters | GFLOPs | mAP50 (COCO) | Speed (ms) |
|---------|-----------|--------|--------------|------------|
| YOLOv8n (nano) | 3.2M | 8.1 | ~37.3 | ~0.99 |
| YOLOv8s (small) | 11.2M | 28.8 | ~44.9 | ~1.20 |
| YOLOv8m (medium) | 25.9M | 78.9 | ~50.2 | ~1.83 |
| YOLOv8l (large) | 43.7M | 165.2 | ~52.9 | ~2.39 |
| YOLOv8x (xlarge) | 68.2M | 257.8 | ~53.9 | ~3.53 |

**L·ª±a ch·ªçn YOLOv8s cho nghi√™n c·ª©u:**
- **L√Ω do**: M·ª•c ti√™u ƒë·∫°t mAP50 = 0.78-0.83, c·∫ßn model c√≥ capacity ƒë·ªß l·ªõn
- **Trade-off**: YOLOv8s c√≥ 11.2M parameters, l·ªõn h∆°n YOLOv8n (3.2M) nh∆∞ng nh·ªè h∆°n YOLOv8m (25.9M)
- **K·∫øt qu·∫£ th·ª±c t·∫ø**: mAP50 = 0.6601, th·∫•p h∆°n k·ª≥ v·ªçng, c√≥ th·ªÉ do model qu√° l·ªõn so v·ªõi dataset size (10k images)

**So s√°nh v·ªõi YOLOv8n:**
- YOLOv8n ph√π h·ª£p h∆°n cho dataset nh·ªè (< 20k images)
- YOLOv8s c√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting v·ªõi dataset 10k images
- ƒê·ªÅ xu·∫•t: Th·ª≠ YOLOv8n trong t∆∞∆°ng lai ƒë·ªÉ so s√°nh

### 3.2. Multi-Object Tracking v·ªõi DeepSORT

#### 3.2.1. T·ªïng quan v·ªÅ Tracking

Multi-Object Tracking (MOT) l√† b√†i to√°n theo d√µi nhi·ªÅu ƒë·ªëi t∆∞·ª£ng qua nhi·ªÅu frames trong video. Kh√°c v·ªõi detection ch·ªâ x·ª≠ l√Ω t·ª´ng frame ƒë·ªôc l·∫≠p, tracking ph·∫£i:
- Duy tr√¨ identity c·ªßa m·ªói ƒë·ªëi t∆∞·ª£ng qua frames
- X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p: xu·∫•t hi·ªán m·ªõi, bi·∫øn m·∫•t, occlusion
- X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p: ID switching, fragmentation

#### 3.2.2. DeepSORT Architecture

DeepSORT (Deep Simple Online and Realtime Tracking) l√† m·ªôt ph∆∞∆°ng ph√°p tracking ph·ªï bi·∫øn, k·∫øt h·ª£p:

**Kalman Filter:**
- D·ª± ƒëo√°n v·ªã tr√≠ c·ªßa ƒë·ªëi t∆∞·ª£ng ·ªü frame ti·∫øp theo
- State vector: [x, y, s, r, x', y', s'] v·ªõi:
  - x, y: center coordinates
  - s: scale (area)
  - r: aspect ratio
  - x', y', s': velocities
- Update state khi c√≥ detection m·ªõi

**Feature Extraction:**
- Trong nghi√™n c·ª©u n√†y, s·ª≠ d·ª•ng histogram-based features (128 dimensions)
- Extract t·ª´ bounding box region: color histograms (B, G, R channels)
- Normalize th√†nh unit vector ƒë·ªÉ t√≠nh cosine similarity

**Association:**
- T√≠nh cost matrix k·∫øt h·ª£p IoU distance v√† feature distance
- Weighted combination: 0.5 √ó IoU_cost + 0.5 √ó Feature_cost
- Hungarian algorithm ƒë·ªÉ t√¨m optimal matching
- Threshold ƒë·ªÉ filter matches c√≥ cost qu√° cao

**Track Management:**
- **New tracks**: T·∫°o track m·ªõi cho unmatched detections
- **Confirmed tracks**: Tracks ƒë√£ match ‚â• min_hits (default: 3) frames
- **Deleted tracks**: Tracks kh√¥ng match trong max_age (default: 30) frames

### 3.3. Dataset v√† Metrics

#### 3.3.1. COCO Dataset

COCO (Common Objects in Context) l√† m·ªôt trong nh·ªØng dataset ph·ªï bi·∫øn nh·∫•t cho object detection:
- **COCO 2014**: 82,081 training labels ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nghi√™n c·ª©u n√†y, 40,504 validation images
- **80 classes**: person, bicycle, car, ..., toothbrush
- **Format**: YOLO format v·ªõi normalized coordinates (x_center, y_center, width, height)

**V·∫•n ƒë·ªÅ Imbalance:**
- Class "person": 7,418 images
- Class "toaster": 25 images
- T·ª∑ l·ªá imbalance: 321:1
- ·∫¢nh h∆∞·ªüng: Model h·ªçc t·ªët classes ph·ªï bi·∫øn, k√©m v·ªõi classes hi·∫øm

#### 3.3.2. Evaluation Metrics

**mAP (mean Average Precision):**
- **mAP50**: Average Precision v·ªõi IoU threshold = 0.5
- **mAP50-95**: Average Precision v·ªõi IoU t·ª´ 0.5 ƒë·∫øn 0.95 (step 0.05)
- T√≠nh cho m·ªói class, sau ƒë√≥ l·∫•y trung b√¨nh

**Precision:**
- T·ª∑ l·ªá detections ƒë√∫ng trong t·ªïng s·ªë detections
- Precision = TP / (TP + FP)
- Trong nghi√™n c·ª©u: 0.7283 (72.83%)

**Recall:**
- T·ª∑ l·ªá ground truth ƒë∆∞·ª£c detect ƒë√∫ng
- Recall = TP / (TP + FN)
- Trong nghi√™n c·ª©u: 0.5933 (59.33%)

**F1-Score:**
- Harmonic mean c·ªßa Precision v√† Recall
- F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
- Trong nghi√™n c·ª©u: 0.6540 (65.40%)
- ƒê√°nh gi√° s·ª± c√¢n b·∫±ng gi·ªØa Precision v√† Recall

**IoU (Intersection over Union):**
- ƒêo ƒë·ªô overlap gi·ªØa predicted box v√† ground truth box
- IoU = Area of Intersection / Area of Union
- Threshold = 0.5 ƒë·ªÉ quy·∫øt ƒë·ªãnh TP/FP

---

## 4. PH√ÇN T√çCH Y√äU C·∫¶U

### 4.1. Y√™u c·∫ßu ch·ª©c nƒÉng

H·ªá th·ªëng c·∫ßn ƒë√°p ·ª©ng c√°c y√™u c·∫ßu ch·ª©c nƒÉng sau:

#### 4.1.1. Real-time Object Detection t·ª´ Camera
- **M√¥ t·∫£**: Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng real-time t·ª´ webcam ho·∫∑c camera device
- **Y√™u c·∫ßu k·ªπ thu·∫≠t**:
  - Frame rate ‚â• 10 FPS ƒë·ªÉ ƒë·∫£m b·∫£o tr·∫£i nghi·ªám m∆∞·ª£t m√†
  - Latency < 200ms per frame
  - H·ªó tr·ª£ nhi·ªÅu resolutions (640√ó480, 1280√ó720)
- **Input**: Video stream t·ª´ camera
- **Output**: ·∫¢nh v·ªõi bounding boxes, class labels, confidence scores

#### 4.1.2. Image Upload v√† Detection
- **M√¥ t·∫£**: Cho ph√©p ng∆∞·ªùi d√πng upload ·∫£nh tƒ©nh ƒë·ªÉ nh·∫≠n di·ªán
- **Y√™u c·∫ßu k·ªπ thu·∫≠t**:
  - H·ªó tr·ª£ formats: JPG, PNG, BMP, WEBP, TIFF
  - Max file size: 10MB
  - Drag & drop interface
- **Input**: Image file t·ª´ user
- **Output**: ·∫¢nh v·ªõi bounding boxes, b·∫£ng k·∫øt qu·∫£ chi ti·∫øt, statistics

#### 4.1.3. Multi-Object Tracking
- **M√¥ t·∫£**: Duy tr√¨ track IDs ·ªïn ƒë·ªãnh cho c√°c ƒë·ªëi t∆∞·ª£ng qua nhi·ªÅu frames
- **Y√™u c·∫ßu k·ªπ thu·∫≠t**:
  - Track ID kh√¥ng thay ƒë·ªïi khi ƒë·ªëi t∆∞·ª£ng di chuy·ªÉn
  - X·ª≠ l√Ω occlusion (ƒë·ªëi t∆∞·ª£ng b·ªã che khu·∫•t)
  - X·ª≠ l√Ω ID switching (tr√°nh nh·∫ßm l·∫´n gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng)
- **Input**: Sequence of frames v·ªõi detections
- **Output**: Tracks v·ªõi stable IDs, history paths

#### 4.1.4. Audio Feedback
- **M√¥ t·∫£**: Ph√°t √¢m k·∫øt qu·∫£ detection b·∫±ng ti·∫øng Vi·ªát cho ng∆∞·ªùi khi·∫øm th·ªã
- **Y√™u c·∫ßu k·ªπ thu·∫≠t**:
  - Text-to-Speech (TTS) s·ª≠ d·ª•ng Web Speech API
  - Gom k·∫øt qu·∫£ theo l·ªõp (v√≠ d·ª•: "Ph√°t hi·ªán 2 xe t·∫£i. Ph√°t hi·ªán 1 ng∆∞·ªùi")
  - Ch·ªâ ƒë·ªçc ƒë·ªëi t∆∞·ª£ng m·ªõi trong camera mode (d·ª±a tr√™n track IDs)
  - H·ªó tr·ª£ b·∫≠t/t·∫Øt audio, ƒë·ªçc l·∫°i
- **Input**: Detection results
- **Output**: Audio speech b·∫±ng ti·∫øng Vi·ªát

#### 4.1.5. Visualization v√† Statistics
- **M√¥ t·∫£**: Hi·ªÉn th·ªã k·∫øt qu·∫£ detection v·ªõi bounding boxes v√† th·ªëng k√™
- **Y√™u c·∫ßu k·ªπ thu·∫≠t**:
  - V·∫Ω bounding boxes v·ªõi m√†u s·∫Øc theo confidence
  - Hi·ªÉn th·ªã class name, confidence score, track ID
  - B·∫£ng k·∫øt qu·∫£ c√≥ th·ªÉ s·∫Øp x·∫øp theo confidence/class
  - Statistics: t·ªïng s·ªë objects, classes, avg confidence
- **Input**: Detection results
- **Output**: Visualized image, results table, statistics

### 4.2. Y√™u c·∫ßu phi ch·ª©c nƒÉng

#### 4.2.1. Performance
- **Frame Rate**: ‚â• 10 FPS trong camera mode
- **Latency**: < 200ms per frame
- **Throughput**: X·ª≠ l√Ω ƒë∆∞·ª£c nhi·ªÅu requests ƒë·ªìng th·ªùi
- **Memory**: S·ª≠ d·ª•ng < 4GB GPU memory

#### 4.2.2. Accuracy
- **mAP50**: 
  - M·ª•c ti√™u t·ªëi thi·ªÉu: ‚â• 0.75 (75%)
  - M·ª•c ti√™u k·ª≥ v·ªçng: 0.78-0.83 (d·ª±a tr√™n balanced dataset v√† model YOLOv8s)
- **Precision**: ‚â• 0.70 (70%)
- **Recall**: ‚â• 0.65 (65%)
- **F1-Score**: ‚â• 0.65 (65%) - ƒë√°nh gi√° s·ª± c√¢n b·∫±ng gi·ªØa Precision v√† Recall
- **K·∫øt qu·∫£ th·ª±c t·∫ø**: mAP50 = 0.6601, Precision = 0.7283, Recall = 0.5933, F1-Score = 0.6540
  - *Precision ƒë·∫°t m·ª•c ti√™u, F1-Score g·∫ßn ƒë·∫°t m·ª•c ti√™u, nh∆∞ng mAP50 v√† Recall th·∫•p h∆°n m·ª•c ti√™u, s·∫Ω ƒë∆∞·ª£c ph√¢n t√≠ch trong ph·∫ßn ƒë√°nh gi√°*

#### 4.2.3. Usability
- **User Interface**: Responsive, d·ªÖ s·ª≠ d·ª•ng, h·ªó tr·ª£ mobile
- **Accessibility**: H·ªó tr·ª£ ng∆∞·ªùi khi·∫øm th·ªã v·ªõi audio feedback
- **Localization**: Giao di·ªán v√† k·∫øt qu·∫£ ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát
- **Error Handling**: Th√¥ng b√°o l·ªói r√µ r√†ng, user-friendly

#### 4.2.4. Scalability
- **Concurrent Users**: H·ªó tr·ª£ nhi·ªÅu sessions ƒë·ªìng th·ªùi
- **Session Management**: T·ª± ƒë·ªông cleanup sessions kh√¥ng ho·∫°t ƒë·ªông (timeout 5 ph√∫t)
- **Resource Management**: T·ªëi ∆∞u memory v√† GPU usage

#### 4.2.5. Security
- **File Upload**: Validate file type, size, sanitize filenames
- **Path Traversal Protection**: NgƒÉn ch·∫∑n directory traversal attacks
- **CORS Configuration**: C·∫•u h√¨nh CORS ƒë·ªÉ b·∫£o m·∫≠t API
- **Input Validation**: Validate thresholds, parameters

### 4.3. Y√™u c·∫ßu k·ªπ thu·∫≠t

#### 4.3.1. Backend
- **Framework**: FastAPI (Python 3.8+)
- **Model**: YOLOv8s (Ultralytics)
- **Tracking**: DeepSORT implementation
- **Dependencies**: 
  - ultralytics==8.3.223
  - opencv-python==4.8.1.78
  - scipy>=1.9.0 (cho Hungarian algorithm)
  - filterpy>=1.4.5 (cho Kalman Filter)

#### 4.3.2. Frontend
- **Framework**: React 18.2.0
- **Styling**: Tailwind CSS 3.3.6
- **HTTP Client**: Axios 1.6.0
- **Audio**: Web Speech API (SpeechSynthesis)

#### 4.3.3. Hardware
- **GPU**: NVIDIA Tesla P100-PCIE-16GB (17.06 GB VRAM)
- **CPU**: Multi-core processor
- **Memory**: ‚â• 8GB RAM
- **Storage**: ‚â• 10GB cho dataset v√† model

#### 4.3.4. Software
- **OS**: Linux (Ubuntu 20.04+)
- **Python**: 3.8+
- **Node.js**: 14+ (khuy·∫øn ngh·ªã 16+)
- **CUDA**: 11.0+ (cho GPU support)

---

## 5. THI·∫æT K·∫æ H·ªÜ TH·ªêNG

### 5.1. Ki·∫øn tr√∫c t·ªïng th·ªÉ

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo ki·∫øn tr√∫c 3 t·∫ßng (3-tier architecture) v·ªõi s·ª± t√°ch bi·ªát r√µ r√†ng gi·ªØa Presentation Layer, Application Layer, v√† Data/Model Layer.

**T·∫ßng 1 - Frontend (Presentation Layer):**
- **Framework**: React 18.2.0 v·ªõi functional components v√† hooks
- **Styling**: Tailwind CSS 3.3.6 cho responsive design
- **State Management**: React useState, useEffect, useRef hooks
- **HTTP Client**: Axios 1.6.0 ƒë·ªÉ giao ti·∫øp v·ªõi backend
- **Audio**: Web Speech API (SpeechSynthesis) cho Text-to-Speech

**T·∫ßng 2 - Backend (Application Layer):**
- **Framework**: FastAPI 0.104.1 (Python async web framework)
- **API Server**: Uvicorn v·ªõi ASGI
- **CORS**: C·∫•u h√¨nh CORS middleware ƒë·ªÉ cho ph√©p frontend k·∫øt n·ªëi
- **Session Management**: Qu·∫£n l√Ω tracking sessions v·ªõi timeout 5 ph√∫t
- **File Handling**: Temporary file storage v·ªõi auto-cleanup

**T·∫ßng 3 - Model Layer:**
- **Detection Model**: YOLOv8s (Ultralytics) - 11.2M parameters
- **Tracking**: DeepSORT implementation v·ªõi Kalman Filter
- **Feature Extraction**: Histogram-based features (128 dimensions)

**Lu·ªìng x·ª≠ l√Ω ch√≠nh:**

1. **Image Upload Mode:**
   ```
   User uploads image ‚Üí Frontend (React) ‚Üí Backend API (/api/detect) 
   ‚Üí ObjectDetector.detect_image() ‚Üí YOLOv8 inference 
   ‚Üí Extract detections ‚Üí Format response ‚Üí Frontend displays results
   ```

2. **Camera Mode:**
   ```
   Camera stream ‚Üí Frontend captures frame ‚Üí Backend API (/api/detect-video)
   ‚Üí VideoTracker.process_frame() ‚Üí YOLOv8 detection + DeepSORT tracking
   ‚Üí Update tracks ‚Üí Format response ‚Üí Frontend displays with track IDs
   ```

### 5.2. L·ª±a ch·ªçn Model

#### 5.2.1. Ph√¢n t√≠ch Dataset Size

Dataset sau x·ª≠ l√Ω c√≥:
- **Training images**: 10,030 ·∫£nh
- **Validation images**: 9,217 ·∫£nh
- **Total**: 19,247 ·∫£nh
- **Classes**: 80 classes
- **Avg per class**: ~125 ·∫£nh (sau khi balanced)

ƒê√¢y l√† m·ªôt dataset t∆∞∆°ng ƒë·ªëi nh·ªè so v·ªõi c√°c dataset l·ªõn nh∆∞ COCO full (82k+ images). V·ªõi dataset size n√†y, vi·ªác l·ª±a ch·ªçn model size l√† r·∫•t quan tr·ªçng.

#### 5.2.2. So s√°nh YOLOv8n vs YOLOv8s

**YOLOv8n (Nano):**
- Parameters: 3.2M
- GFLOPs: 8.1
- ∆Øu ƒëi·ªÉm:
  - Nh·∫π, nhanh
  - Ph√π h·ª£p v·ªõi dataset nh·ªè (< 20k images)
  - √çt kh·∫£ nƒÉng overfitting
- Nh∆∞·ª£c ƒëi·ªÉm:
  - Capacity th·∫•p, c√≥ th·ªÉ kh√¥ng ƒë·ªß cho 80 classes
  - mAP th·∫•p h∆°n tr√™n COCO full dataset

**YOLOv8s (Small):**
- Parameters: 11.2M
- GFLOPs: 28.8
- ∆Øu ƒëi·ªÉm:
  - Capacity cao h∆°n, ph√π h·ª£p cho nhi·ªÅu classes
  - C√≥ th·ªÉ ƒë·∫°t mAP cao h∆°n v·ªõi dataset t·ªët
- Nh∆∞·ª£c ƒëi·ªÉm:
  - N·∫∑ng h∆°n, ch·∫≠m h∆°n
  - C√≥ th·ªÉ overfitting v·ªõi dataset nh·ªè

#### 5.2.3. Quy·∫øt ƒë·ªãnh l·ª±a ch·ªçn

**L·ª±a ch·ªçn: YOLOv8s**

**L√Ω do:**
1. **M·ª•c ti√™u mAP cao**: M·ª•c ti√™u ƒë·∫°t mAP50 = 0.78-0.83, c·∫ßn model c√≥ capacity ƒë·ªß l·ªõn
2. **80 classes**: S·ªë l∆∞·ª£ng classes l·ªõn (80) ƒë√≤i h·ªèi model c√≥ ƒë·ªß capacity ƒë·ªÉ h·ªçc
3. **Balanced dataset**: Dataset ƒë√£ ƒë∆∞·ª£c balanced, c√≥ th·ªÉ t·∫≠n d·ª•ng ƒë∆∞·ª£c capacity c·ªßa model l·ªõn h∆°n
4. **GPU ƒë·ªß m·∫°nh**: Tesla P100 v·ªõi 17GB VRAM c√≥ th·ªÉ handle YOLOv8s v·ªõi batch size h·ª£p l√Ω

**K·∫øt qu·∫£ th·ª±c t·∫ø:**
- mAP50 = 0.6601 (th·∫•p h∆°n baseline 0.6925)
- C√≥ th·ªÉ do model qu√° l·ªõn so v·ªõi dataset size ‚Üí overfitting ti·ªÅm ·∫©n
- **Lesson learned**: N√™n th·ª≠ YOLOv8n ƒë·ªÉ so s√°nh trong t∆∞∆°ng lai

#### 5.2.4. ƒê·ªÅ xu·∫•t c·∫£i thi·ªán

D·ª±a tr√™n k·∫øt qu·∫£, ƒë·ªÅ xu·∫•t:
1. **Th·ª≠ YOLOv8n**: V·ªõi dataset 10k images, YOLOv8n c√≥ th·ªÉ ph√π h·ª£p h∆°n
2. **Fine-tuning**: N·∫øu d√πng YOLOv8s, c·∫ßn ƒëi·ªÅu ch·ªânh hyperparameters (LR, augmentation, regularization)
3. **Data augmentation m·∫°nh h∆°n**: TƒÉng augmentation ƒë·ªÉ tƒÉng effective dataset size

### 5.3. Backend Design

#### 5.3.1. API Endpoints

**GET /api/model-info**
- Tr·∫£ v·ªÅ th√¥ng tin model: s·ªë classes, danh s√°ch classes, default thresholds
- Response: JSON v·ªõi model metadata

**POST /api/detect**
- Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng trong ·∫£nh tƒ©nh
- Input: Multipart form data (file, conf_threshold, iou_threshold)
- Output: JSON v·ªõi detections, image_base64, statistics
- Timeout: 30 seconds

**POST /api/detect-video**
- Nh·∫≠n di·ªán v√† tracking ƒë·ªëi t∆∞·ª£ng trong video frame
- Input: Multipart form data (file, conf_threshold, iou_threshold, session_id)
- Output: JSON v·ªõi tracks, image_base64, statistics, session_id
- Timeout: 30 seconds

**POST /api/reset-tracking-session**
- Reset tracking session (x√≥a t·∫•t c·∫£ tracks)
- Input: session_id
- Output: Success/failure message

**POST /api/compare-thresholds**
- So s√°nh k·∫øt qu·∫£ detection v·ªõi nhi·ªÅu confidence thresholds kh√°c nhau
- Input: Multipart form data (file, thresholds: JSON array nh∆∞ "[0.1, 0.25, 0.5, 0.75]")
- Output: JSON v·ªõi comparisons cho m·ªói threshold (count, classes)
- Timeout: 60 seconds
- Use case: Gi√∫p ng∆∞·ªùi d√πng ch·ªçn threshold ph√π h·ª£p b·∫±ng c√°ch so s√°nh s·ªë l∆∞·ª£ng detections v√† classes ·ªü c√°c m·ª©c threshold kh√°c nhau
- Gi·ªõi h·∫°n: T·ªëi ƒëa 10 thresholds ƒë∆∞·ª£c ph√©p so s√°nh trong m·ªôt request

#### 5.3.2. ObjectDetector Class

Wrapper class cho YOLO model v·ªõi c√°c ph∆∞∆°ng th·ª©c ch√≠nh:

**C√°c ph∆∞∆°ng th·ª©c:**
- `__init__()`: Kh·ªüi t·∫°o v·ªõi model path v√† thresholds (conf_threshold=0.25, iou_threshold=0.45)
- `detect_image()`: Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng trong m·ªôt ·∫£nh, tr·∫£ v·ªÅ results v√† annotated image
- `detect_folder()`: Nh·∫≠n di·ªán t·∫•t c·∫£ ·∫£nh trong m·ªôt folder
- `compare_thresholds()`: So s√°nh k·∫øt qu·∫£ v·ªõi nhi·ªÅu confidence thresholds kh√°c nhau

**Ch·ª©c nƒÉng:**
- Load YOLOv8 model t·ª´ file `best.pt`
- Th·ª±c hi·ªán inference v·ªõi configurable thresholds
- Tr·∫£ v·ªÅ results v√† annotated images

#### 5.3.3. VideoTracker Class

K·∫øt h·ª£p YOLO detection v√† DeepSORT tracking v·ªõi c√°c ph∆∞∆°ng th·ª©c:

**C√°c ph∆∞∆°ng th·ª©c:**
- `__init__()`: Kh·ªüi t·∫°o v·ªõi model path v√† thresholds, t·∫°o ObjectDetector v√† DeepSORT tracker
- `process_frame()`: X·ª≠ l√Ω m·ªôt frame: detect v·ªõi YOLO, track v·ªõi DeepSORT, tr·∫£ v·ªÅ results v√† tracks
- `reset()`: Reset tracker, x√≥a t·∫•t c·∫£ tracks

**Ch·ª©c nƒÉng:**
- YOLO detection cho m·ªói frame
- DeepSORT tracking ƒë·ªÉ duy tr√¨ track IDs
- Format tracks th√†nh dict cho API response
- V·∫Ω bounding boxes v·ªõi track IDs v√† colors

#### 5.3.4. Session Management

- **Session Storage**: Dictionary l∆∞u tr·ªØ tracker instances theo session_id
- **Session Timeout**: 5 ph√∫t (300 seconds) - t·ª± ƒë·ªông cleanup
- **Session ID**: Format `session_{timestamp}_{random}` ƒë·ªÉ ƒë·∫£m b·∫£o unique
- **Cleanup**: T·ª± ƒë·ªông x√≥a sessions kh√¥ng ho·∫°t ƒë·ªông

### 5.4. Frontend Design

#### 5.4.1. Component Architecture

**App.jsx (Main Component):**
- Qu·∫£n l√Ω mode: 'home', 'camera', 'image'
- State management: selectedFile, detections, modelInfo
- Audio service integration

**HomeView.jsx:**
- M√†n h√¨nh ch·ªçn ch·∫ø ƒë·ªô: Camera ho·∫∑c Image
- Navigation buttons

**CameraView.jsx:**
- Real-time camera stream v·ªõi MediaDevices API
- Frame capture v√† g·ª≠i ƒë·∫øn backend
- Bounding boxes overlay v·ªõi track IDs
- Audio feedback cho ƒë·ªëi t∆∞·ª£ng m·ªõi
- Performance optimization: frame skipping, image compression

**ImageUpload.jsx:**
- Drag & drop interface
- File validation (type, size)
- Preview image

**ImagePreview.jsx:**
- Hi·ªÉn th·ªã ·∫£nh v·ªõi bounding boxes
- Zoom & pan functionality

**ResultsTable.jsx:**
- B·∫£ng k·∫øt qu·∫£ v·ªõi sortable columns
- Statistics display

#### 5.4.2. Audio Service

**audioService.js:**
- Text-to-Speech s·ª≠ d·ª•ng Web Speech API
- Gom k·∫øt qu·∫£ theo l·ªõp (v√≠ d·ª•: "Ph√°t hi·ªán 2 xe t·∫£i. Ph√°t hi·ªán 1 ng∆∞·ªùi")
- Ch·ªâ ƒë·ªçc ƒë·ªëi t∆∞·ª£ng m·ªõi trong camera mode (d·ª±a tr√™n track IDs)
- Queue management ƒë·ªÉ tr√°nh spam audio
- Debounce mechanism

**T√≠nh nƒÉng:**
- `speakDetections()`: Ph√°t √¢m nhi·ªÅu detections, gom theo l·ªõp
- `speakSystemMessage()`: Ph√°t √¢m th√¥ng b√°o h·ªá th·ªëng
- `stop()`: D·ª´ng audio hi·ªán t·∫°i
- `setEnabled()`: B·∫≠t/t·∫Øt audio

#### 5.4.3. Performance Optimization

**Frame Skipping:**
- Skip frame n·∫øu ƒëang detect frame tr∆∞·ªõc
- Tr√°nh queue qu√° nhi·ªÅu requests

**Image Compression:**
- Resize frame t·ª´ 640√ó480 xu·ªëng 320√ó240
- JPEG quality = 0.6 (gi·∫£m t·ª´ 0.8)
- Gi·∫£m file size ~75%, tƒÉng t·ªëc ƒë·ªô upload

**Request Queue:**
- S·ª≠ d·ª•ng AbortController ƒë·ªÉ cancel requests c≈©
- Tr√°nh race conditions
- Ch·ªâ gi·ªØ 1 request active t·∫°i m·ªôt th·ªùi ƒëi·ªÉm

### 5.5. Security v√† Error Handling

#### 5.5.1. Security Features

- **Path Traversal Protection**: Sanitize filenames, ch·ªâ cho ph√©p alphanumeric v√† m·ªôt s·ªë k√Ω t·ª± ƒë·∫∑c bi·ªát
- **File Size Validation**: Max 10MB per file
- **File Type Validation**: Ch·ªâ cho ph√©p image formats (JPG, PNG, BMP, WEBP, TIFF)
- **CORS Configuration**: Configurable via environment variable
- **Input Validation**: Validate thresholds (0-1 range)

#### 5.5.2. Error Handling

- **Timeout Handling**: 30s cho detection, 60s cho batch
- **GPU Error Handling**: Catch CUDA errors, fallback messages
- **Memory Error Handling**: Catch OOM errors, suggest smaller images
- **Network Error Handling**: Retry logic, user-friendly messages

---

## 6. CHU·∫®N B·ªä D·ªÆ LI·ªÜU

### 6.1. Dataset g·ªëc - COCO 2014

**Th·ªëng k√™ ban ƒë·∫ßu:**
- **Training images**: 82,081 ·∫£nh
- **Validation images**: 40,504 ·∫£nh
- **Total images**: 122,585 ·∫£nh
- **Classes**: 80 classes
- **Format**: YOLO format v·ªõi normalized coordinates

**V·∫•n ƒë·ªÅ Imbalance nghi√™m tr·ªçng:**

B·∫£ng ph√¢n b·ªë m·ªôt s·ªë classes (top v√† bottom):

| Class | S·ªë ·∫£nh | T·ª∑ l·ªá |
|-------|--------|-------|
| person | 7,418 | 9.0% |
| car | 2,197 | 2.7% |
| bicycle | 713 | 0.9% |
| ... | ... | ... |
| toaster | 25 | 0.03% |
| hair drier | 15 | 0.02% |

**T·ª∑ l·ªá imbalance**: 321:1 (person : toaster)

**·∫¢nh h∆∞·ªüng:**
- Model h·ªçc t·ªët classes ph·ªï bi·∫øn (person, car)
- Model k√©m v·ªõi classes hi·∫øm (toaster, hair drier)
- Precision v√† Recall kh√¥ng ƒë·ªìng ƒë·ªÅu gi·ªØa c√°c classes

### 6.2. Pipeline x·ª≠ l√Ω d·ªØ li·ªáu

Pipeline ƒë∆∞·ª£c thi·∫øt k·∫ø th√†nh 6 b∆∞·ªõc ch√≠nh:

#### 6.2.1. B∆∞·ªõc 1: Ph√¢n t√≠ch Dataset

**M·ª•c ti√™u**: Qu√©t to√†n b·ªô dataset ƒë·ªÉ hi·ªÉu ph√¢n b·ªë classes

**Quy tr√¨nh:**
1. Load class names t·ª´ `coco.names` (80 classes)
2. Qu√©t 82,081 training labels
3. ƒê·∫øm s·ªë ·∫£nh ch·ª©a m·ªói class
4. Ph√¢n lo·∫°i classes:
   - **Classes ƒë·ªß** (‚â•250 ·∫£nh): 78 classes
   - **Classes thi·∫øu** (<250 ·∫£nh): 2 classes

**K·∫øt qu·∫£:**
- 78 classes c√≥ ‚â•250 ·∫£nh
- 2 classes c√≥ <250 ·∫£nh
- T·ªïng s·ªë ·∫£nh unique: ~20,000 ·∫£nh (m·ªôt ·∫£nh c√≥ th·ªÉ ch·ª©a nhi·ªÅu classes)

#### 6.2.2. B∆∞·ªõc 2: Smart Sampling

**M·ª•c ti√™u**: Ch·ªçn 250 ·∫£nh t·ªët nh·∫•t cho m·ªói class (classes ƒë·ªß)

**Thu·∫≠t to√°n Quality Score:**

M·ªói ·∫£nh ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng quality score d·ª±a tr√™n:

1. **S·ªë classes trong ·∫£nh** (weight: 3.0)
   - ·∫¢nh ch·ª©a nhi·ªÅu classes ‚Üí score cao h∆°n
   - L√Ω do: ·∫¢nh ƒëa d·∫°ng gi√∫p model h·ªçc t·ªët h∆°n

2. **Bbox area** (weight: 2.0 ho·∫∑c 1.0)
   - Area 0.05-0.6: +2.0 (optimal size)
   - Area 0.01-0.05: +1.0 (small but acceptable)
   - Area <0.01 ho·∫∑c >0.6: +0.0 (too small ho·∫∑c too large)
   - L√Ω do: Bbox qu√° nh·ªè ho·∫∑c qu√° l·ªõn kh√≥ detect

3. **V·ªã tr√≠ bbox** (weight: 1.0)
   - Center (x, y) trong kho·∫£ng [0.2, 0.8]: +1.0
   - L√Ω do: Bbox ·ªü trung t√¢m th∆∞·ªùng d·ªÖ detect h∆°n

**C√¥ng th·ª©c t√≠nh Quality Score:**
- score = (s·ªë_classes_trong_·∫£nh √ó 3.0) + bbox_area_score + bbox_position_score
- Trong ƒë√≥:
  - bbox_area_score: +2.0 n·∫øu area 0.05-0.6, +1.0 n·∫øu area 0.01-0.05, +0.0 n·∫øu kh√°c
  - bbox_position_score: +1.0 n·∫øu center (x,y) trong [0.2, 0.8], +0.0 n·∫øu kh√°c

**Quy tr√¨nh:**
1. V·ªõi m·ªói class ƒë·ªß (‚â•250 ·∫£nh):
   - T√≠nh quality score cho t·∫•t c·∫£ ·∫£nh ch·ª©a class ƒë√≥
   - S·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
   - Ch·ªçn top 250 ·∫£nh
2. V·ªõi m·ªói class thi·∫øu (<250 ·∫£nh):
   - Gi·ªØ t·∫•t c·∫£ ·∫£nh c√≥ s·∫µn

**K·∫øt qu·∫£:**
- 9,809 ·∫£nh ƒë∆∞·ª£c ch·ªçn t·ª´ smart sampling
- M·ªói class ƒë·ªß c√≥ ƒë√∫ng 250 ·∫£nh ƒë∆∞·ª£c ch·ªçn
- Classes thi·∫øu gi·ªØ nguy√™n t·∫•t c·∫£ ·∫£nh

#### 6.2.3. B∆∞·ªõc 3: Augmentation

**M·ª•c ti√™u**: TƒÉng s·ªë l∆∞·ª£ng ·∫£nh cho classes thi·∫øu

**K·ªπ thu·∫≠t Augmentation:**
1. **Horizontal Flip**: Flip ·∫£nh theo tr·ª•c d·ªçc, ƒëi·ªÅu ch·ªânh bbox coordinates
2. **Brightness Adjustment**: Nh√¢n pixel values v·ªõi random factor [0.85, 1.15]

**Quy tr√¨nh:**
1. V·ªõi m·ªói class thi·∫øu:
   - T√≠nh s·ªë ·∫£nh c·∫ßn: `need = 250 - current_count`
   - Random ch·ªçn ·∫£nh t·ª´ dataset hi·ªán c√≥
   - √Åp d·ª•ng augmentation
   - L∆∞u ·∫£nh m·ªõi v·ªõi suffix `_aug{i}.jpg`
   - ƒêi·ªÅu ch·ªânh bbox coordinates cho flip

**K·∫øt qu·∫£:**
- 221 ·∫£nh ƒë∆∞·ª£c augment
- T·ªïng training images: 10,030 ·∫£nh (9,809 + 221)

**L∆∞u √Ω:**
- Ch·ªâ augment cho classes thi·∫øu
- Validate bbox coordinates sau augmentation
- Lo·∫°i b·ªè bbox kh√¥ng h·ª£p l·ªá (area < 0.01)

#### 6.2.4. B∆∞·ªõc 4: Validation Processing

**M·ª•c ti√™u**: T·∫°o validation set balanced

**Quy tr√¨nh:**
1. Qu√©t 10,000 validation labels (gi·ªõi h·∫°n ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian)
2. V·ªõi m·ªói class:
   - Sample ng·∫´u nhi√™n t·ªëi ƒëa 250 ·∫£nh
3. Copy ·∫£nh v√† labels t∆∞∆°ng ·ª©ng

**K·∫øt qu·∫£:**
- 9,217 validation images
- Ph√¢n b·ªë t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng gi·ªØa c√°c classes

#### 6.2.5. B∆∞·ªõc 5: T·∫°o Config

**M·ª•c ti√™u**: T·∫°o file `data.yaml` cho YOLO format

**N·ªôi dung file data.yaml:**
- path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset root
- train: Th∆∞ m·ª•c ch·ª©a training images (images/train)
- val: Th∆∞ m·ª•c ch·ª©a validation images (images/val)
- nc: S·ªë l∆∞·ª£ng classes (80)
- names: Dictionary mapping class ID sang class name (0: person, 1: bicycle, 2: car, ...)

#### 6.2.6. B∆∞·ªõc 6: T·ªïng k·∫øt

**K·∫øt qu·∫£ cu·ªëi c√πng:**

| Metric | Gi√° tr·ªã |
|--------|---------|
| Training images | 10,030 |
| Validation images | 9,217 |
| Total images | 19,247 |
| Classes | 80 |
| Target per class | 250 |
| Augmented images | 221 |
| Imbalance ratio | ~1:1 (t·ª´ 321:1) |

**So s√°nh Before/After:**

| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Training images | 82,081 | 10,030 | -87.8% |
| Imbalance ratio | 321:1 | ~1:1 | -99.7% |
| Avg per class | Varies | ~250 | Balanced |

**L∆∞u √Ω quan tr·ªçng:**
- T·ªïng ·∫£nh (10,030) < 80 √ó 250 = 20,000 v√¨ m·ªôt ·∫£nh c√≥ th·ªÉ ch·ª©a nhi·ªÅu classes
- ƒêi·ªÅu n√†y l√† **ƒë√∫ng** cho YOLO training - m·ªôt ·∫£nh c√≥ th·ªÉ train nhi·ªÅu classes c√πng l√∫c
- V√≠ d·ª•: ·∫¢nh c√≥ person + car s·∫Ω ƒë∆∞·ª£c ƒë·∫øm cho c·∫£ 2 classes

### 6.3. Ph√¢n t√≠ch Dataset sau x·ª≠ l√Ω

**Ph√¢n b·ªë classes (10 classes ƒë·∫ßu):**

| Class ID | Class Name | Selected Images | Total Available |
|----------|------------|-----------------|-----------------|
| 0 | person | 250 | 7,418 |
| 1 | bicycle | 250 | 713 |
| 2 | car | 250 | 2,197 |
| 3 | motorbike | 250 | 400 |
| 4 | aeroplane | 250 | 255 |
| 5 | bus | 250 | 521 |
| 6 | train | 250 | 269 |
| 7 | truck | 250 | 1,155 |
| 8 | boat | 250 | 359 |
| 9 | traffic light | 250 | 599 |

**ƒê·∫∑c ƒëi·ªÉm:**
- T·∫•t c·∫£ 80 classes ƒë·ªÅu c√≥ ‚â•250 ·∫£nh (sau augmentation)
- Ph√¢n b·ªë ƒë·ªìng ƒë·ªÅu gi·ªØa c√°c classes
- Quality score ƒë·∫£m b·∫£o ch·ªçn ·∫£nh t·ªët nh·∫•t

---

## 7. HU·∫§N LUY·ªÜN M√î H√åNH

### 7.1. M√¥i tr∆∞·ªùng Training

**Hardware:**
- **GPU**: Tesla P100-PCIE-16GB
- **VRAM**: 17.06 GB
- **CUDA**: Version 11.0+
- **CPU**: Multi-core processor

**Software:**
- **Python**: 3.10.12
- **PyTorch**: 2.0.0
- **Ultralytics**: 8.3.233
- **CUDA**: Enabled v·ªõi cuDNN

**Dataset:**
- **Training**: 10,030 images
- **Validation**: 9,217 images
- **Classes**: 80
- **Format**: YOLO format

**Th·ªùi gian Training:**
- **Start**: 2025-11-30 11:30:41
- **End**: 2025-11-30 19:16:10
- **Duration**: ~8 gi·ªù (7 gi·ªù 45 ph√∫t)

### 7.2. T·ªëi ∆∞u h√≥a cho GPU P100

#### 7.2.1. Auto-detection v√† Configuration

H·ªá th·ªëng t·ª± ƒë·ªông ph√°t hi·ªán GPU v√† t·ªëi ∆∞u h√≥a:

**GPU Detection:**
- T·ª± ƒë·ªông ph√°t hi·ªán CUDA availability
- L·∫•y GPU name: Tesla P100-PCIE-16GB
- T√≠nh to√°n VRAM: 17.06 GB t·ª´ device properties

**Auto-tuning Batch Size:**
- **YOLOv8s**: Batch size = 28 (t·ª± ƒë·ªông t√≠nh to√°n)
- **L√Ω do**: Model 's' l·ªõn h∆°n, c·∫ßn gi·∫£m batch ƒë·ªÉ fit VRAM
- **Trade-off**: Batch nh·ªè h∆°n ‚Üí training ch·∫≠m h∆°n nh∆∞ng ·ªïn ƒë·ªãnh h∆°n

**Workers:**
- **Data Loading**: 20 workers (t·ªëi ƒëa)
- **L√Ω do**: TƒÉng t·ªëc ƒë·ªô load data, gi·∫£m bottleneck

**Cache:**
- **Image Cache**: Enabled
- **L√Ω do**: Cache images trong RAM ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô training

#### 7.2.2. Mixed Precision Training (AMP)

**Automatic Mixed Precision (AMP):**
- **Enabled**: True
- **L√Ω do**: S·ª≠ d·ª•ng FP16 cho m·ªôt s·ªë operations, gi·∫£m memory usage v√† tƒÉng t·ªëc ƒë·ªô
- **Benefit**: TƒÉng t·ªëc ƒë·ªô ~1.5-2x, gi·∫£m memory ~50%

**AMP Checks:**
- System t·ª± ƒë·ªông ki·ªÉm tra compatibility
- Passed ‚úÖ trong training log

### 7.3. Hyperparameters

#### 7.3.1. Model Configuration

- **Model**: YOLOv8s (Small variant)
- **Parameters**: 11,166,560 (11.2M)
- **GFLOPs**: 28.8
- **Pretrained**: True (s·ª≠ d·ª•ng pretrained weights t·ª´ COCO)

#### 7.3.2. Training Configuration

**Epochs:**
- **Value**: 120 epochs
- **L√Ω do**: Dataset balanced, c·∫ßn nhi·ªÅu epochs ƒë·ªÉ convergence
- **Patience**: 0 (kh√¥ng early stopping, train ƒë·ªß 120 epochs)

**Image Size:**
- **Value**: 640√ó640 pixels
- **L√Ω do**: Standard size cho YOLOv8, balance gi·ªØa accuracy v√† speed

**Batch Size:**
- **Value**: 28
- **L√Ω do**: T·ªëi ∆∞u cho P100 v·ªõi YOLOv8s, fit trong VRAM
- **Effective Batch**: 64 (nbs=64, gradient accumulation)

#### 7.3.3. Optimizer Configuration

**Optimizer:**
- **Type**: SGD (Stochastic Gradient Descent)
- **L√Ω do**: SGD ·ªïn ƒë·ªãnh h∆°n AdamW cho balanced dataset
- **Momentum**: 0.937
- **Weight Decay**: 0.0005

**Learning Rate:**
- **Initial (lr0)**: 0.002
- **Final (lrf)**: 0.0001
- **Schedule**: Cosine annealing
- **Warmup**: 5 epochs
- **Warmup Momentum**: 0.8
- **Warmup Bias LR**: 0.1

**L√Ω do LR cao:**
- Balanced dataset ‚Üí c√≥ th·ªÉ h·ªçc nhanh h∆°n
- Cosine schedule ‚Üí gi·∫£m d·∫ßn v·ªÅ cu·ªëi training

#### 7.3.4. Loss Functions

**Loss Weights:**
- **Box Loss**: 7.5 (localization)
- **Class Loss**: 0.5 (classification - gi·∫£m v√¨ data balanced)
- **DFL Loss**: 1.5 (distribution focal loss)
- **Label Smoothing**: 0.0 (t·∫Øt v√¨ data t·ªët)

**L√Ω do gi·∫£m Class Loss:**
- Dataset ƒë√£ balanced ‚Üí kh√¥ng c·∫ßn weight cao cho classification
- T·∫≠p trung v√†o localization (Box Loss)

#### 7.3.5. Augmentation Strategy

**Augmentation Parameters (v·ª´a ph·∫£i v√¨ data ƒë√£ balanced):**

| Parameter | Value | M√¥ t·∫£ |
|-----------|-------|-------|
| hsv_h | 0.015 | Hue adjustment |
| hsv_s | 0.7 | Saturation adjustment |
| hsv_v | 0.4 | Value (brightness) adjustment |
| degrees | 15.0 | Rotation (¬±15 degrees) |
| translate | 0.15 | Translation (15% of image size) |
| scale | 0.9 | Scale variation |
| shear | 5.0 | Shear transformation |
| perspective | 0.0005 | Perspective transformation |
| flipud | 0.0 | Vertical flip (disabled) |
| fliplr | 0.5 | Horizontal flip (50% probability) |
| mosaic | 1.0 | Mosaic augmentation (enabled) |
| mixup | 0.15 | Mixup augmentation (15% probability) |
| copy_paste | 0.1 | Copy-paste augmentation (10% probability) |

**L√Ω do augmentation v·ª´a ph·∫£i:**
- Dataset ƒë√£ balanced ‚Üí kh√¥ng c·∫ßn augmentation m·∫°nh
- Tr√°nh over-augmentation ‚Üí gi·∫£m noise

### 7.4. Training Process

#### 7.4.1. Training Speed

**Per Image Speed:**
- **Preprocess**: 0.6ms
- **Inference**: 3.8ms
- **Loss**: 0.0ms (negligible)
- **Postprocess**: 0.9ms
- **Total**: ~5.3ms per image

**Throughput:**
- V·ªõi batch size 28: ~5,283 images/second
- M·ªôt epoch (10,030 images): ~1.9 seconds
- 120 epochs: ~228 seconds (3.8 minutes) cho inference
- T·ªïng th·ªùi gian 8 gi·ªù bao g·ªìm: data loading, validation, logging, etc.

#### 7.4.2. Validation

**Validation Frequency:**
- **Every**: 1 epoch
- **Validation Set**: 9,217 images
- **Validation Time**: ~1 ph√∫t 13 gi√¢y per epoch (577 batches √ó 7.9 it/s)

**Metrics Tracked:**
- mAP50 (primary metric)
- mAP50-95
- Precision
- Recall
- Per-class metrics

#### 7.4.3. Model Saving

**Save Strategy:**
- **Save Period**: 10 epochs
- **Best Model**: T·ª± ƒë·ªông save model c√≥ mAP50 cao nh·∫•t
- **Last Model**: Save model cu·ªëi c√πng
- **Location**: `runs/detect/animal_balanced/weights/`

**Files Saved:**
- `best.pt`: Best model (highest mAP50)
- `last.pt`: Last epoch model
- `results.png`: Training curves
- `confusion_matrix.png`: Confusion matrix
- `val_batch*.jpg`: Validation examples

### 7.5. Training Curves v√† Monitoring

**Metrics ƒë∆∞·ª£c theo d√µi:**

1. **Loss Curves:**
   - Train/Val Box Loss
   - Train/Val Class Loss
   - Train/Val DFL Loss
   - Total Loss

2. **mAP Curves:**
   - mAP50 (primary)
   - mAP50-95

3. **Precision/Recall/F1 Curves:**
   - Precision
   - Recall
   - F1-Score (harmonic mean c·ªßa Precision v√† Recall)

**Ph√¢n t√≠ch Training:**
- Loss gi·∫£m d·∫ßn v√† h·ªôi t·ª•
- mAP50 tƒÉng d·∫ßn trong qu√° tr√¨nh training
- Validation metrics t∆∞∆°ng ƒë·ªëi ·ªïn ƒë·ªãnh (kh√¥ng overfitting nghi√™m tr·ªçng)

**K·∫øt qu·∫£ cu·ªëi c√πng (Epoch 120):**
- mAP50: 0.6601
- mAP50-95: 0.3895
- Precision: 0.7283
- Recall: 0.5933
- F1-Score: 0.6540

---

## 8. K·∫æT QU·∫¢

### 8.1. K·∫øt qu·∫£ Training

#### 8.1.1. Overall Metrics

Sau 120 epochs training tr√™n balanced dataset v·ªõi YOLOv8s, m√¥ h√¨nh ƒë·∫°t ƒë∆∞·ª£c c√°c metrics sau tr√™n validation set (9,217 images):

| Metric | Gi√° tr·ªã | M√¥ t·∫£ |
|--------|---------|-------|
| **mAP50** | 0.6601 (66.01%) | Mean Average Precision v·ªõi IoU=0.5 |
| **mAP50-95** | 0.3895 (38.95%) | Mean Average Precision v·ªõi IoU t·ª´ 0.5-0.95 |
| **Precision** | 0.7283 (72.83%) | T·ª∑ l·ªá detections ƒë√∫ng |
| **Recall** | 0.5933 (59.33%) | T·ª∑ l·ªá ground truth ƒë∆∞·ª£c detect |
| **F1-Score** | 0.6540 (65.40%) | Harmonic mean c·ªßa Precision v√† Recall |

**Ph√¢n t√≠ch:**
- **Precision cao (72.83%)**: Model c√≥ ƒë·ªô tin c·∫≠y cao, √≠t false positives
- **Recall th·∫•p (59.33%)**: Model conservative, b·ªè s√≥t m·ªôt s·ªë ƒë·ªëi t∆∞·ª£ng
- **F1-Score (65.40%)**: Ph·∫£n √°nh s·ª± c√¢n b·∫±ng gi·ªØa Precision v√† Recall, cho th·∫•y model c√≥ performance trung b√¨nh t·ªët
- **Trade-off**: Precision-Recall trade-off cho th·∫•y model ∆∞u ti√™n accuracy h∆°n coverage

#### 8.1.2. So s√°nh v·ªõi Baseline

| Metric | Baseline (Imbalanced) | Balanced (YOLOv8s) | Change |
|--------|----------------------|-------------------|--------|
| mAP50 | 0.6925 (69.25%) | 0.6601 (66.01%) | **-4.7%** |
| Precision | - | 0.7283 (72.83%) | - |
| Recall | - | 0.5933 (59.33%) | - |
| F1-Score | - | 0.6540 (65.40%) | - |

**Ph√¢n t√≠ch k·∫øt qu·∫£:**
- K·∫øt qu·∫£ **th·∫•p h∆°n baseline** 4.7%, kh√¥ng ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u c·∫£i thi·ªán
- C√≥ th·ªÉ do c√°c nguy√™n nh√¢n:
  1. **Model qu√° l·ªõn**: YOLOv8s (11.2M params) c√≥ th·ªÉ qu√° l·ªõn cho dataset 10k images ‚Üí overfitting
  2. **Dataset size nh·ªè**: 10k images c√≥ th·ªÉ kh√¥ng ƒë·ªß ƒë·ªÉ model l·ªõn h·ªçc t·ªët
  3. **Hyperparameters**: C√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh LR, augmentation, ho·∫∑c regularization

#### 8.1.3. Per-class Performance

**Top 10 Classes (mAP50 cao nh·∫•t):**

*L∆∞u √Ω: C·ªôt "Images" l√† s·ªë ·∫£nh trong validation set (9,217 ·∫£nh) c√≥ ch·ª©a class t∆∞∆°ng ·ª©ng.*

| Class | mAP50 | Precision | Recall | Images (val) |
|-------|-------|-----------|--------|--------------|
| zebra | 0.945 | 0.881 | 0.896 | 143 |
| cat | 0.940 | 0.890 | 0.892 | 344 |
| giraffe | 0.936 | 0.922 | 0.892 | 207 |
| bear | 0.931 | 0.720 | 0.941 | 76 |
| elephant | 0.919 | 0.863 | 0.879 | 202 |
| train | 0.905 | 0.873 | 0.845 | 272 |
| fire hydrant | 0.910 | 0.887 | 0.862 | 153 |
| dog | 0.870 | 0.852 | 0.792 | 338 |
| stop sign | 0.872 | 0.800 | 0.834 | 169 |
| person | 0.779 | 0.832 | 0.674 | 5,013 |

**Bottom 10 Classes (mAP50 th·∫•p nh·∫•t):**

| Class | mAP50 | Precision | Recall | Images (val) |
|-------|-------|-----------|--------|--------------|
| hair drier | 0.249 | 0.267 | 0.467 | 15 |
| book | 0.270 | 0.493 | 0.182 | 430 |
| carrot | 0.410 | 0.459 | 0.447 | 137 |
| apple | 0.437 | 0.498 | 0.424 | 124 |
| bench | 0.427 | 0.654 | 0.371 | 397 |
| toaster | 0.507 | 0.281 | 0.600 | 24 |
| handbag | 0.335 | 0.576 | 0.281 | 540 |
| backpack | 0.388 | 0.632 | 0.303 | 445 |
| knife | 0.360 | 0.650 | 0.258 | 330 |
| spoon | 0.373 | 0.681 | 0.249 | 283 |

**Nh·∫≠n x√©t:**
- **Classes t·ªët**: Th∆∞·ªùng l√† ƒë·ªông v·∫≠t (zebra, cat, giraffe, bear, elephant) ho·∫∑c objects l·ªõn, d·ªÖ nh·∫≠n di·ªán
- **Classes k√©m**: Th∆∞·ªùng l√† objects nh·ªè (hair drier, toaster), ho·∫∑c objects c√≥ nhi·ªÅu bi·∫øn th·ªÉ (book, handbag)
- **Person class**: mAP50 = 0.779, t·ªët nh∆∞ng kh√¥ng ph·∫£i t·ªët nh·∫•t (do c√≥ nhi·ªÅu bi·∫øn th·ªÉ)

### 8.2. Real-time Performance

#### 8.2.1. Inference Speed

**Per Image Speed:**
- **Preprocess**: 0.6ms
- **Inference**: 3.8ms
- **Postprocess**: 0.9ms
- **Total**: ~5.3ms per image

**Throughput:**
- V·ªõi batch size 1: ~189 FPS (l√Ω thuy·∫øt)
- V·ªõi batch size 28: ~5,283 images/second

**Real-time Camera Performance:**
- **Frame Rate**: ~10-15 FPS (v·ªõi frame skipping v√† image compression)
- **Latency**: ~100-200ms per frame (bao g·ªìm network, processing, display)
- **Memory Usage**: ~2-3GB GPU memory

#### 8.2.2. Tracking Performance

**Track ID Stability:**
- Track IDs ·ªïn ƒë·ªãnh qua nhi·ªÅu frames
- ID switching rate: Th·∫•p (< 5% trong c√°c test cases)
- Occlusion handling: T·ªët, c√≥ th·ªÉ track l·∫°i sau khi b·ªã che khu·∫•t

**Association Accuracy:**
- IoU matching: Ch√≠nh x√°c cho objects di chuy·ªÉn ch·∫≠m
- Feature matching: H·ªØu √≠ch cho objects c√≥ appearance ·ªïn ƒë·ªãnh
- Combined cost: Weighted combination (0.5 IoU + 0.5 Feature) cho k·∫øt qu·∫£ t·ªët

### 8.3. System Performance

#### 8.3.1. Web Application Performance

**Frontend:**
- **Load Time**: < 2 seconds
- **Responsiveness**: Smooth v·ªõi 60 FPS UI
- **Memory**: ~100-200MB browser memory

**Backend:**
- **API Response Time**: 
  - `/api/detect`: ~100-200ms (single image)
  - `/api/detect-video`: ~150-250ms (frame v·ªõi tracking)
- **Concurrent Requests**: H·ªó tr·ª£ nhi·ªÅu sessions ƒë·ªìng th·ªùi
- **Session Management**: Auto-cleanup sau 5 ph√∫t kh√¥ng ho·∫°t ƒë·ªông

#### 8.3.2. Resource Usage

**GPU:**
- **Training**: ~15-16GB VRAM (v·ªõi batch size 28)
- **Inference**: ~2-3GB VRAM
- **Utilization**: ~80-90% trong training, ~40-60% trong inference

**CPU:**
- **Data Loading**: 20 workers, ~50-70% CPU usage
- **Inference**: Single-threaded, ~10-20% CPU usage

**Memory:**
- **Training**: ~8-10GB RAM
- **Inference**: ~2-4GB RAM

### 8.4. Error Analysis

#### 8.4.1. Common Errors

**False Positives:**
- Objects t∆∞∆°ng t·ª± nhau (v√≠ d·ª•: handbag vs backpack)
- Background patterns b·ªã nh·∫ßm l√† objects
- Small objects v·ªõi low confidence

**False Negatives:**
- Objects qu√° nh·ªè (< 32√ó32 pixels)
- Objects b·ªã che khu·∫•t nhi·ªÅu
- Objects ·ªü g√≥c ·∫£nh ho·∫∑c ngo√†i v√πng quan t√¢m
- Objects v·ªõi appearance kh√¥ng quen thu·ªôc

**Localization Errors:**
- Bounding boxes kh√¥ng ch√≠nh x√°c cho objects c√≥ shape ph·ª©c t·∫°p
- Multiple objects g·∫ßn nhau b·ªã merge th√†nh m·ªôt box

#### 8.4.2. Per-class Error Patterns

**Classes c√≥ nhi·ªÅu False Positives:**
- book (Precision = 0.493): D·ªÖ nh·∫ßm v·ªõi c√°c objects ph·∫≥ng kh√°c
- handbag (Precision = 0.576): T∆∞∆°ng t·ª± backpack, suitcase
- knife (Precision = 0.650): Nh·ªè, kh√≥ ph√¢n bi·ªát

**Classes c√≥ nhi·ªÅu False Negatives:**
- book (Recall = 0.182): R·∫•t th·∫•p, c√≥ th·ªÉ do qu√° nhi·ªÅu bi·∫øn th·ªÉ
- spoon (Recall = 0.249): Nh·ªè, kh√≥ detect
- handbag (Recall = 0.281): T∆∞∆°ng t·ª±

---

## 9. DEMO / ·ª®NG D·ª§NG

### 9.1. Giao di·ªán H·ªá th·ªëng

#### 9.1.1. Home Screen

M√†n h√¨nh ch√≠nh cung c·∫•p 2 l·ª±a ch·ªçn:

**üì∑ Camera Mode:**
- Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng real-time t·ª´ webcam
- Hi·ªÉn th·ªã bounding boxes v·ªõi track IDs
- Audio feedback cho ƒë·ªëi t∆∞·ª£ng m·ªõi
- FPS counter v√† detection rate

**üñºÔ∏è Image Mode:**
- Upload ·∫£nh tƒ©nh ƒë·ªÉ nh·∫≠n di·ªán
- Drag & drop interface
- Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi bounding boxes
- B·∫£ng k·∫øt qu·∫£ chi ti·∫øt

#### 9.1.2. Camera Mode Interface

**Layout:**
- **Left Panel (2/3 width)**: Video feed v·ªõi bounding boxes overlay
- **Right Panel (1/3 width)**: Results table v·ªõi active tracks
- **Bottom Bar**: Status indicators v√† audio controls

**Features:**
- Real-time detection v·ªõi frame rate ~10-15 FPS
- Track IDs hi·ªÉn th·ªã tr√™n bounding boxes
- Color coding:
  - Green: New tracks
  - Blue: High confidence (>0.7)
  - Yellow: Medium confidence (0.5-0.7)
  - Red: Low confidence (<0.5)
- Detection indicator khi ƒëang x·ª≠ l√Ω
- Object count badge

#### 9.1.3. Image Mode Interface

**Layout:**
- **Left Panel (2/3 width)**: Image preview v·ªõi bounding boxes
- **Right Panel (1/3 width)**: Detect button, audio controls, results table

**Features:**
- Image upload v·ªõi drag & drop
- Zoom & pan ƒë·ªÉ xem chi ti·∫øt
- Results table sortable theo confidence/class
- Statistics: total objects, classes, avg confidence
- Audio feedback v·ªõi gom theo l·ªõp

### 9.2. T√≠nh nƒÉng Ch√≠nh

#### 9.2.1. Real-time Camera Detection

**Workflow:**
1. User ch·ªçn "Camera" mode
2. H·ªá th·ªëng y√™u c·∫ßu quy·ªÅn truy c·∫≠p camera
3. Camera stream b·∫Øt ƒë·∫ßu
4. M·ªói frame ƒë∆∞·ª£c capture v√† g·ª≠i ƒë·∫øn backend
5. Backend x·ª≠ l√Ω v·ªõi YOLO + DeepSORT
6. K·∫øt qu·∫£ tr·∫£ v·ªÅ v·ªõi track IDs
7. Frontend hi·ªÉn th·ªã bounding boxes v√† update results table

**Optimizations:**
- Frame skipping: Skip n·∫øu ƒëang detect
- Image compression: Resize 320√ó240, quality 0.6
- Request queue: Ch·ªâ 1 request active
- AbortController: Cancel requests c≈©

#### 9.2.2. Image Upload v√† Detection

**Workflow:**
1. User upload ·∫£nh (drag & drop ho·∫∑c click)
2. File validation (type, size)
3. Preview ·∫£nh
4. User click "Detect Objects"
5. Backend x·ª≠ l√Ω v·ªõi YOLO
6. K·∫øt qu·∫£ hi·ªÉn th·ªã v·ªõi bounding boxes
7. Results table v√† statistics
8. Audio feedback (n·∫øu enabled)

**Supported Formats:**
- JPG, JPEG
- PNG
- BMP
- WEBP
- TIFF

**Max File Size:** 10MB

#### 9.2.3. Multi-Object Tracking

**Features:**
- Stable track IDs qua nhi·ªÅu frames
- Track history (last 30 states)
- Occlusion handling
- ID switching prevention

**Visualization:**
- Track ID hi·ªÉn th·ªã tr√™n bounding box
- Color coding theo confidence v√† is_new
- "NEW" label cho tracks m·ªõi

#### 9.2.4. Audio Feedback

**Text-to-Speech (TTS):**
- S·ª≠ d·ª•ng Web Speech API
- Language: Vietnamese (vi-VN)
- Rate: 1.0 (normal speed)
- Volume: 1.0 (maximum)

**Gom k·∫øt qu·∫£ theo l·ªõp:**
- Thay v√¨: "Ph√°t hi·ªán xe t·∫£i. Ph√°t hi·ªán xe t·∫£i. Ph√°t hi·ªán ng∆∞·ªùi."
- Gom th√†nh: "Ph√°t hi·ªán 2 xe t·∫£i. Ph√°t hi·ªán 1 ng∆∞·ªùi."

**Camera Mode:**
- Ch·ªâ ƒë·ªçc ƒë·ªëi t∆∞·ª£ng m·ªõi (d·ª±a tr√™n track IDs)
- Tr√°nh spam audio khi ƒë·ªëi t∆∞·ª£ng v·∫´n c√≤n trong frame
- Debounce mechanism ƒë·ªÉ tr√°nh ƒë·ªçc qu√° nhi·ªÅu

**Controls:**
- B·∫≠t/t·∫Øt audio
- ƒê·ªçc l·∫°i k·∫øt qu·∫£ g·∫ßn nh·∫•t
- Auto-stop khi chuy·ªÉn mode

### 9.3. Use Cases

#### 9.3.1. Surveillance v√† An ninh

**·ª®ng d·ª•ng:**
- Gi√°m s√°t khu v·ª±c c√¥ng c·ªông
- Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng ƒë√°ng ng·ªù
- ƒê·∫øm s·ªë l∆∞·ª£ng ng∆∞·ªùi/vehicles
- Tracking ƒë·ªëi t∆∞·ª£ng qua nhi·ªÅu cameras

**T√≠nh nƒÉng h·ªØu √≠ch:**
- Real-time detection
- Multi-object tracking
- Statistics v√† reporting

#### 9.3.2. Accessibility - H·ªó tr·ª£ Ng∆∞·ªùi khi·∫øm th·ªã

**·ª®ng d·ª•ng:**
- M√¥ t·∫£ m√¥i tr∆∞·ªùng xung quanh b·∫±ng audio
- Ph√°t hi·ªán obstacles v√† objects
- H∆∞·ªõng d·∫´n navigation

**T√≠nh nƒÉng h·ªØu √≠ch:**
- Audio feedback b·∫±ng ti·∫øng Vi·ªát
- Gom k·∫øt qu·∫£ theo l·ªõp (d·ªÖ hi·ªÉu)
- Ch·ªâ ƒë·ªçc ƒë·ªëi t∆∞·ª£ng m·ªõi (tr√°nh spam)

#### 9.3.3. Education v√† H·ªçc t·∫≠p

**·ª®ng d·ª•ng:**
- H·ªçc v·ªÅ object detection
- Demo c√°c m√¥ h√¨nh AI
- Th·ª±c h√†nh v·ªõi real-world data

**T√≠nh nƒÉng h·ªØu √≠ch:**
- Visual feedback v·ªõi bounding boxes
- Statistics v√† metrics
- Interactive interface

### 9.4. Screenshots v√† Demo

**C√°c m√†n h√¨nh ch√≠nh:**
1. Home screen v·ªõi 2 options
2. Camera mode v·ªõi video feed v√† results
3. Image mode v·ªõi uploaded image v√† results
4. Results table v·ªõi sortable columns
5. Audio controls v√† settings

**Demo scenarios:**
- Real-time detection trong ph√≤ng
- Upload ·∫£nh street scene
- Tracking multiple people
- Audio feedback demonstration

---

## 10. ƒê√ÅNH GI√Å & TH·∫¢O LU·∫¨N

### 10.1. ƒê√°nh gi√° K·∫øt qu·∫£

#### 10.1.1. Th√†nh c√¥ng

**1. Pipeline x·ª≠ l√Ω d·ªØ li·ªáu hi·ªáu qu·∫£:**
- Smart sampling algorithm th√†nh c√¥ng trong vi·ªác ch·ªçn ·∫£nh ch·∫•t l∆∞·ª£ng cao
- Dataset ƒë∆∞·ª£c balanced t·ª´ 321:1 xu·ªëng ~1:1
- Augmentation strategy ph√π h·ª£p cho classes thi·∫øu
- T·ªïng th·ªùi gian x·ª≠ l√Ω: ~20 ph√∫t cho 82k images

**2. H·ªá th·ªëng web application ho√†n ch·ªânh:**
- Real-time camera detection ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh
- Multi-object tracking v·ªõi DeepSORT duy tr√¨ track IDs t·ªët
- Audio feedback h·ªØu √≠ch cho ng∆∞·ªùi khi·∫øm th·ªã
- UI/UX responsive v√† user-friendly

**3. T·ªëi ∆∞u h√≥a performance:**
- Frame skipping v√† image compression gi·∫£m load
- Request queue tr√°nh race conditions
- Session management t·ª± ƒë·ªông cleanup

**4. Precision v√† F1-Score t·ªët:**
- Precision = 72.83% cho th·∫•y model c√≥ ƒë·ªô tin c·∫≠y cao
- F1-Score = 65.40% ph·∫£n √°nh s·ª± c√¢n b·∫±ng t·ªët gi·ªØa Precision v√† Recall
- √çt false positives, ph√π h·ª£p cho applications c·∫ßn accuracy

#### 10.1.2. H·∫°n ch·∫ø

**1. mAP50 th·∫•p h∆°n baseline:**
- mAP50 = 66.01% vs baseline 69.25% (-4.7%)
- Kh√¥ng ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u 0.78-0.83
- C·∫ßn ph√¢n t√≠ch v√† c·∫£i thi·ªán

**2. Recall th·∫•p:**
- Recall = 59.33% cho th·∫•y model b·ªè s√≥t nhi·ªÅu ƒë·ªëi t∆∞·ª£ng
- Model qu√° conservative
- C·∫ßn ƒëi·ªÅu ch·ªânh confidence threshold ho·∫∑c loss weights

**3. M·ªôt s·ªë classes c√≥ performance k√©m:**
- hair drier: mAP50 = 0.249 (r·∫•t th·∫•p)
- book: mAP50 = 0.270 (r·∫•t th·∫•p)
- toaster: mAP50 = 0.507 (th·∫•p)
- C√≥ th·ªÉ do √≠t d·ªØ li·ªáu ho·∫∑c objects qu√° nh·ªè

**4. Model size c√≥ th·ªÉ kh√¥ng ph√π h·ª£p:**
- YOLOv8s (11.2M params) c√≥ th·ªÉ qu√° l·ªõn cho dataset 10k images
- C√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting ti·ªÅm ·∫©n

### 10.2. Ph√¢n t√≠ch Nguy√™n nh√¢n

#### 10.2.1. T·∫°i sao mAP50 th·∫•p h∆°n baseline?

**Nguy√™n nh√¢n c√≥ th·ªÉ:**

1. **Model qu√° l·ªõn so v·ªõi dataset size:**
   - YOLOv8s (11.2M params) vs dataset 10k images
   - Rule of thumb: C·∫ßn ~100-1000 samples per parameter
   - 10k images c√≥ th·ªÉ kh√¥ng ƒë·ªß cho 11.2M params
   - **Gi·∫£i ph√°p**: Th·ª≠ YOLOv8n (3.2M params) ph√π h·ª£p h∆°n

2. **Dataset size nh·ªè:**
   - Gi·∫£m t·ª´ 82k xu·ªëng 10k (87.8% reduction)
   - M·∫•t nhi·ªÅu diversity v√† variation
   - **Gi·∫£i ph√°p**: TƒÉng dataset size ho·∫∑c augmentation m·∫°nh h∆°n

3. **Hyperparameters ch∆∞a t·ªëi ∆∞u:**
   - Learning rate c√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh
   - Augmentation c√≥ th·ªÉ c·∫ßn m·∫°nh h∆°n
   - Regularization c√≥ th·ªÉ c·∫ßn tƒÉng
   - **Gi·∫£i ph√°p**: Hyperparameter tuning

4. **Loss weights:**
   - Class loss = 0.5 (th·∫•p) c√≥ th·ªÉ kh√¥ng ƒë·ªß
   - Box loss = 7.5 (cao) c√≥ th·ªÉ qu√° t·∫≠p trung v√†o localization
   - **Gi·∫£i ph√°p**: ƒêi·ªÅu ch·ªânh loss weights

#### 10.2.2. T·∫°i sao Recall th·∫•p?

**Nguy√™n nh√¢n:**

1. **Model conservative:**
   - Precision cao (72.83%) nh∆∞ng Recall th·∫•p (59.33%)
   - Model ∆∞u ti√™n accuracy h∆°n coverage
   - C√≥ th·ªÉ do confidence threshold cao

2. **Small objects:**
   - Nhi·ªÅu objects nh·ªè b·ªã b·ªè s√≥t
   - YOLOv8 c√≥ th·ªÉ k√©m v·ªõi objects < 32√ó32 pixels

3. **Occlusion:**
   - Objects b·ªã che khu·∫•t kh√≥ detect
   - C·∫ßn data augmentation v·ªõi occlusion

**Gi·∫£i ph√°p:**
- Gi·∫£m confidence threshold
- TƒÉng class loss weight
- Augmentation v·ªõi small objects v√† occlusion

#### 10.2.3. T·∫°i sao m·ªôt s·ªë classes k√©m?

**Classes k√©m (mAP50 < 0.5):**
- hair drier (0.249): Ch·ªâ c√≥ 15 images ‚Üí qu√° √≠t d·ªØ li·ªáu
- book (0.270): Qu√° nhi·ªÅu bi·∫øn th·ªÉ, kh√≥ h·ªçc
- carrot (0.410): Nh·ªè, kh√≥ detect
- apple (0.437): T∆∞∆°ng t·ª± carrot

**Nguy√™n nh√¢n:**
1. **√çt d·ªØ li·ªáu**: hair drier ch·ªâ c√≥ 15 images (sau augmentation)
2. **High variation**: book c√≥ nhi·ªÅu lo·∫°i, kh√≥ generalize
3. **Small size**: carrot, apple th∆∞·ªùng nh·ªè trong ·∫£nh
4. **Similar appearance**: D·ªÖ nh·∫ßm v·ªõi objects t∆∞∆°ng t·ª±

**Gi·∫£i ph√°p:**
- TƒÉng d·ªØ li·ªáu cho classes thi·∫øu
- Augmentation m·∫°nh h∆°n
- Focal loss ƒë·ªÉ t·∫≠p trung v√†o hard examples

### 10.3. So s√°nh v·ªõi C√°c Ph∆∞∆°ng ph√°p Kh√°c

#### 10.3.1. Baseline Comparison

| Method | Dataset | mAP50 | Notes |
|--------|---------|-------|-------|
| Baseline | Imbalanced (82k) | 0.6925 | Full dataset, imbalanced |
| Our Method | Balanced (10k) | 0.6601 | Balanced, YOLOv8s |
| Difference | - | **-4.7%** | Lower than baseline |

**Ph√¢n t√≠ch:**
- Balanced dataset kh√¥ng c·∫£i thi·ªán k·∫øt qu·∫£ nh∆∞ k·ª≥ v·ªçng
- C√≥ th·ªÉ do dataset size nh·ªè ho·∫∑c model kh√¥ng ph√π h·ª£p
- C·∫ßn th·ª≠ YOLOv8n ho·∫∑c tƒÉng dataset size

#### 10.3.2. Model Size Comparison

**ƒê·ªÅ xu·∫•t so s√°nh (ch∆∞a th·ª±c hi·ªán):**

| Model | Parameters | Dataset Size | Expected mAP50 |
|-------|-----------|--------------|----------------|
| YOLOv8n | 3.2M | 10k | 0.70-0.75 (∆∞·ªõc t√≠nh) |
| YOLOv8s | 11.2M | 10k | 0.6601 (th·ª±c t·∫ø) |
| YOLOv8s | 11.2M | 20k+ | 0.75+ (∆∞·ªõc t√≠nh) |

**K·∫øt lu·∫≠n:**
- YOLOv8n c√≥ th·ªÉ ph√π h·ª£p h∆°n cho dataset 10k images
- YOLOv8s c·∫ßn dataset l·ªõn h∆°n ƒë·ªÉ ph√°t huy capacity

### 10.4. Lessons Learned

#### 10.4.1. Model Size vs Dataset Size

**Lesson:**
- Model size ph·∫£i ph√π h·ª£p v·ªõi dataset size
- Rule of thumb: ~100-1000 samples per parameter
- YOLOv8s (11.2M params) c·∫ßn ~1-10M samples ƒë·ªÉ optimal
- Dataset 10k images ‚Üí n√™n d√πng YOLOv8n (3.2M params)

**Application:**
- Khi ch·ªçn model, c·∫ßn xem x√©t dataset size
- Kh√¥ng ph·∫£i model l·ªõn h∆°n lu√¥n t·ªët h∆°n
- C·∫ßn balance gi·ªØa capacity v√† overfitting risk

#### 10.4.2. Balanced Dataset kh√¥ng ƒë·∫£m b·∫£o c·∫£i thi·ªán

**Lesson:**
- Balanced dataset l√† c·∫ßn thi·∫øt nh∆∞ng kh√¥ng ƒë·ªß
- C·∫ßn k·∫øt h·ª£p v·ªõi model size ph√π h·ª£p
- C·∫ßn hyperparameters t·ªëi ∆∞u
- C·∫ßn ƒë·ªß d·ªØ li·ªáu cho m·ªói class

**Application:**
- Balanced dataset l√† b∆∞·ªõc ƒë·∫ßu, kh√¥ng ph·∫£i gi·∫£i ph√°p cu·ªëi c√πng
- C·∫ßn xem x√©t nhi·ªÅu y·∫øu t·ªë: model, hyperparameters, augmentation

#### 10.4.3. Precision vs Recall Trade-off

**Lesson:**
- Model c√≥ th·ªÉ ∆∞u ti√™n Precision ho·∫∑c Recall
- C·∫ßn ƒëi·ªÅu ch·ªânh loss weights v√† thresholds
- T√πy application m√† ch·ªçn trade-off ph√π h·ª£p

**Application:**
- Surveillance: C·∫ßn Recall cao (kh√¥ng b·ªè s√≥t)
- Medical: C·∫ßn Precision cao (√≠t false positives)
- General: C·∫ßn balance c·∫£ hai

#### 10.4.4. Quality Score Algorithm

**Lesson:**
- Smart sampling v·ªõi quality score hi·ªáu qu·∫£
- Ch·ªçn ·∫£nh t·ªët quan tr·ªçng h∆°n s·ªë l∆∞·ª£ng
- Quality > Quantity trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p

**Application:**
- Khi c√≥ dataset l·ªõn, n√™n ch·ªçn subset ch·∫•t l∆∞·ª£ng cao
- Quality score c√≥ th·ªÉ customize cho t·ª´ng application

---

## 11. K·∫æT LU·∫¨N & H∆Ø·ªöNG PH√ÅT TRI·ªÇN

### 11.1. K·∫øt lu·∫≠n

Nghi√™n c·ª©u n√†y ƒë√£ x√¢y d·ª±ng th√†nh c√¥ng m·ªôt h·ªá th·ªëng nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng ho√†n ch·ªânh v·ªõi c√°c th√†nh ph·∫ßn ch√≠nh:

**1. Pipeline x·ª≠ l√Ω d·ªØ li·ªáu th√¥ng minh:**
- Ph√°t tri·ªÉn thu·∫≠t to√°n smart sampling d·ª±a tr√™n quality score
- C√¢n b·∫±ng dataset t·ª´ 321:1 xu·ªëng ~1:1
- Gi·∫£m dataset t·ª´ 82k xu·ªëng 10k images nh∆∞ng v·∫´n gi·ªØ ch·∫•t l∆∞·ª£ng

**2. Training m√¥ h√¨nh YOLOv8s:**
- T·ªëi ∆∞u h√≥a cho GPU Tesla P100
- Training 120 epochs trong 8 gi·ªù
- ƒê·∫°t ƒë∆∞·ª£c mAP50 = 66.01%, Precision = 72.83%, Recall = 59.33%, F1-Score = 65.40%

**3. H·ªá th·ªëng web application:**
- Real-time camera detection v·ªõi tracking
- Image upload v√† detection
- Audio feedback b·∫±ng ti·∫øng Vi·ªát
- UI/UX responsive v√† user-friendly

**4. Ph√¢n t√≠ch v√† ƒë√°nh gi√°:**
- So s√°nh v·ªõi baseline v√† ph√¢n t√≠ch nguy√™n nh√¢n
- ƒê∆∞a ra lessons learned v√† ƒë·ªÅ xu·∫•t c·∫£i thi·ªán

M·∫∑c d√π k·∫øt qu·∫£ mAP50 th·∫•p h∆°n baseline (-4.7%), nghi√™n c·ª©u ƒë√£ cung c·∫•p insights quan tr·ªçng v·ªÅ m·ªëi quan h·ªá gi·ªØa model size v√† dataset size, g·ª£i √Ω r·∫±ng YOLOv8n c√≥ th·ªÉ ph√π h·ª£p h∆°n cho dataset 10k images.

### 11.2. ƒê√≥ng g√≥p

**1. Smart Sampling Algorithm:**
- Quality score d·ª±a tr√™n s·ªë classes, bbox area, v√† v·ªã tr√≠
- Hi·ªáu qu·∫£ trong vi·ªác ch·ªçn ·∫£nh ch·∫•t l∆∞·ª£ng cao
- C√≥ th·ªÉ √°p d·ª•ng cho c√°c dataset kh√°c

**2. T·ªëi ∆∞u h√≥a Training cho P100:**
- Auto-detection GPU v√† t·ªëi ∆∞u batch size
- Mixed Precision Training (AMP)
- Workers v√† cache optimization

**3. H·ªá th·ªëng Application ho√†n ch·ªânh:**
- Real-time tracking v·ªõi DeepSORT
- Audio feedback cho accessibility
- Performance optimization (frame skipping, compression)

**4. Ph√¢n t√≠ch v√† Insights:**
- M·ªëi quan h·ªá model size vs dataset size
- Precision-Recall trade-off analysis
- Per-class performance analysis

### 11.3. H·∫°n ch·∫ø

**1. K·∫øt qu·∫£ kh√¥ng ƒë·∫°t m·ª•c ti√™u:**
- mAP50 = 66.01% < m·ª•c ti√™u 78-83%
- Th·∫•p h∆°n baseline 4.7%

**2. Model size c√≥ th·ªÉ kh√¥ng ph√π h·ª£p:**
- YOLOv8s (11.2M params) c√≥ th·ªÉ qu√° l·ªõn cho 10k images
- Ch∆∞a th·ª≠ YOLOv8n ƒë·ªÉ so s√°nh

**3. Dataset size nh·ªè:**
- Gi·∫£m 87.8% t·ª´ 82k xu·ªëng 10k
- C√≥ th·ªÉ m·∫•t diversity

**4. M·ªôt s·ªë classes performance k√©m:**
- hair drier, book, carrot c√≥ mAP50 r·∫•t th·∫•p
- C·∫ßn th√™m d·ªØ li·ªáu ho·∫∑c augmentation

### 11.4. H∆∞·ªõng ph√°t tri·ªÉn

#### 11.4.1. Model v√† Training

**1. Th·ª≠ YOLOv8n:**
- YOLOv8n (3.2M params) ph√π h·ª£p h∆°n v·ªõi dataset 10k images
- So s√°nh k·∫øt qu·∫£ v·ªõi YOLOv8s
- C√≥ th·ªÉ ƒë·∫°t mAP50 cao h∆°n

**2. Hyperparameter Tuning:**
- Learning rate scheduling
- Augmentation strategy
- Loss weights optimization
- Regularization techniques

**3. Data Augmentation m·∫°nh h∆°n:**
- TƒÉng effective dataset size
- Mixup, CutMix, Mosaic
- Synthetic data generation

**4. Transfer Learning:**
- Fine-tuning t·ª´ pretrained model
- Domain adaptation
- Multi-task learning

#### 11.4.2. Dataset

**1. TƒÉng Dataset Size:**
- Th√™m d·ªØ li·ªáu t·ª´ c√°c ngu·ªìn kh√°c
- Data augmentation m·∫°nh h∆°n
- Synthetic data generation

**2. C·∫£i thi·ªán Classes thi·∫øu:**
- Thu th·∫≠p th√™m d·ªØ li·ªáu cho hair drier, toaster
- Augmentation t·∫≠p trung cho classes k√©m
- Active learning ƒë·ªÉ ch·ªçn ·∫£nh quan tr·ªçng

**3. Dataset Diversity:**
- Th√™m c√°c scenarios kh√°c nhau
- ƒêi·ªÅu ki·ªán √°nh s√°ng, g√≥c ch·ª•p ƒëa d·∫°ng
- Background v√† context ƒëa d·∫°ng

#### 11.4.3. Tracking

**1. N√¢ng c·∫•p Feature Extraction:**
- Thay histogram-based b·∫±ng CNN-based features
- S·ª≠ d·ª•ng ReID (Re-identification) models
- ResNet ho·∫∑c MobileNet cho feature extraction

**2. C·∫£i thi·ªán Association:**
- Adaptive cost matrix weights
- Temporal consistency
- Appearance v√† motion models

**3. Occlusion Handling:**
- Better prediction khi b·ªã che khu·∫•t
- Long-term tracking
- Re-identification sau occlusion

#### 11.4.4. Application

**1. Mobile Application:**
- iOS v√† Android apps
- Edge deployment v·ªõi TensorFlow Lite
- On-device inference

**2. Video Processing:**
- Batch video processing
- Video analysis v√† reporting
- Export results to video

**3. Advanced Features:**
- Object counting
- Behavior analysis
- Alert system
- Multi-camera support

**4. Performance Optimization:**
- Model quantization
- Pruning
- Knowledge distillation
- Faster inference

#### 11.4.5. Accessibility

**1. C·∫£i thi·ªán Audio Feedback:**
- Natural language generation
- Context-aware descriptions
- Priority-based announcements

**2. Multi-language Support:**
- H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ
- Language detection
- Customizable translations

**3. Haptic Feedback:**
- Vibration patterns
- Spatial audio
- Multi-modal feedback

---

## 12. T√ÄI LI·ªÜU THAM KH·∫¢O

### 12.1. Papers v√† Research

1. Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). "You Only Look Once: Unified, Real-Time Object Detection." *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.

2. Redmon, J., & Farhadi, A. (2017). "YOLO9000: Better, Faster, Stronger." *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.

3. Redmon, J., & Farhadi, A. (2018). "YOLOv3: An Incremental Improvement." *arXiv preprint arXiv:1804.02767*.

4. Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020). "YOLOv4: Optimal Speed and Accuracy of Object Detection." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*.

5. Ultralytics. (2023). "YOLOv8 Documentation." *Ultralytics*. https://docs.ultralytics.com/

6. Wojke, N., Bewley, A., & Paulus, D. (2017). "Simple Online and Realtime Tracking with a Deep Association Metric." *Proceedings of the IEEE International Conference on Image Processing (ICIP)*.

7. Bewley, A., Ge, Z., Ott, L., Ramos, F., & Upcroft, B. (2016). "Simple Online and Realtime Tracking." *Proceedings of the IEEE International Conference on Image Processing (ICIP)*.

8. Lin, T. Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., ... & Zitnick, C. L. (2014). "Microsoft COCO: Common Objects in Context." *European Conference on Computer Vision (ECCV)*.

### 12.2. Documentation v√† Frameworks

9. Ultralytics. (2023). "Ultralytics YOLOv8." *GitHub*. https://github.com/ultralytics/ultralytics

10. FastAPI. (2023). "FastAPI Documentation." *FastAPI*. https://fastapi.tiangolo.com/

11. React. (2023). "React Documentation." *React*. https://react.dev/

12. Tailwind CSS. (2023). "Tailwind CSS Documentation." *Tailwind CSS*. https://tailwindcss.com/

13. PyTorch. (2023). "PyTorch Documentation." *PyTorch*. https://pytorch.org/docs/

14. OpenCV. (2023). "OpenCV Documentation." *OpenCV*. https://docs.opencv.org/

### 12.3. Datasets

15. Lin, T. Y., et al. (2014). "COCO Dataset." *Common Objects in Context*. https://cocodataset.org/

16. COCO 2014 Dataset for YOLOv3. (2023). *Kaggle*. https://www.kaggle.com/datasets/

### 12.4. Tools v√† Libraries

17. Scipy. (2023). "Scipy Documentation." *Scipy*. https://docs.scipy.org/

18. FilterPy. (2023). "FilterPy Documentation." *FilterPy*. https://filterpy.readthedocs.io/

19. Axios. (2023). "Axios Documentation." *Axios*. https://axios-http.com/

20. Web Speech API. (2023). "MDN Web Docs." *Mozilla Developer Network*. https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API

---

**K·∫øt th√∫c b√°o c√°o**

---

